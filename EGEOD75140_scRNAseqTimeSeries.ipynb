{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aVyxmKdciHHu"
   },
   "source": [
    "# Seeding the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "l4_IVh_Rip3a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL']='2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "ZKLAJ5UGMV4E"
   },
   "outputs": [],
   "source": [
    "# Set seed value\n",
    "seed_value = 56\n",
    "import os\n",
    "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
    "# 2. Set `python` built-in pseudo-random generator at a fixed value\n",
    "import random\n",
    "random.seed(seed_value)\n",
    "# 3. Set `numpy` pseudo-random generator at a fixed value\n",
    "import numpy as np\n",
    "np.random.seed(seed_value)\n",
    "# 4. Set `tensorflow` pseudo-random generator at a fixed value\n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(seed_value)\n",
    "# 5. Configure a new global `tensorflow` session\n",
    "from keras import backend as K\n",
    "session_conf = tf.compat.v1.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n",
    "sess = tf.compat.v1.Session(graph=tf.compat.v1.get_default_graph(), config=session_conf)\n",
    "tf.compat.v1.keras.backend.set_session(sess)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "46Oj4L3ajCGy"
   },
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "g9GvpQWtMSt8"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.io import mmread\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C1Vs4mp1iMLL"
   },
   "source": [
    "# Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PhMIuQyp7x_o"
   },
   "outputs": [],
   "source": [
    "dir = '/home/DibyenduBSeal/DBS_HPC/scRNAseqTimeSeries/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cbYYxgs2MYAU",
    "outputId": "02e6056a-8d67-402b-ba45-ae48aac6e8f5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25592x734 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 6360759 stored elements in COOrdinate format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = mmread(dir+'Data/E-GEOD-75140/E-GEOD-75140.aggregated_filtered_normalised_counts.mtx')\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vtrkIbcwQqyB",
    "outputId": "e4555804-f97a-44a4-e808-e92155ad43d4"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.861691920073795"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparsity=636075900/(25592*734)\n",
    "sparsity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HnKRW6_oiQ1s"
   },
   "source": [
    "# Pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CE_BXDcjvQ4"
   },
   "source": [
    "Converting sparse matrix into dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sZ5yKoiGMawQ",
    "outputId": "519f01b6-50f7-4207-cffb-1ea4ecf71f19"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.2461763e+02, 1.4229472e+02, 1.1054401e+03, ..., 1.7544176e+01,\n",
       "        1.3709451e+00, 1.4930003e+02],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 1.3130432e+02, ..., 1.1754379e+01,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       ...,\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [0.0000000e+00, 0.0000000e+00, 0.0000000e+00, ..., 0.0000000e+00,\n",
       "        0.0000000e+00, 0.0000000e+00],\n",
       "       [9.9968230e-01, 3.3200428e+01, 4.2365917e+01, ..., 5.9442020e+01,\n",
       "        3.4273627e+00, 2.0139720e+01]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_arr = X.toarray()\n",
    "X_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "riCrj5PdG8u3",
    "outputId": "aded71ee-023a-4a17-99b8-6501083498f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25592, 734)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "fsn6_0zMj251",
    "outputId": "54cdf631-0d6b-4c46-beca-bdd0783179af"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>724</th>\n",
       "      <th>725</th>\n",
       "      <th>726</th>\n",
       "      <th>727</th>\n",
       "      <th>728</th>\n",
       "      <th>729</th>\n",
       "      <th>730</th>\n",
       "      <th>731</th>\n",
       "      <th>732</th>\n",
       "      <th>733</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "      <td>25592.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>39.074711</td>\n",
       "      <td>39.074714</td>\n",
       "      <td>39.074712</td>\n",
       "      <td>39.074708</td>\n",
       "      <td>39.074708</td>\n",
       "      <td>39.074711</td>\n",
       "      <td>39.074712</td>\n",
       "      <td>39.074715</td>\n",
       "      <td>39.074711</td>\n",
       "      <td>39.074710</td>\n",
       "      <td>...</td>\n",
       "      <td>39.074718</td>\n",
       "      <td>39.074709</td>\n",
       "      <td>39.074713</td>\n",
       "      <td>39.074711</td>\n",
       "      <td>39.074708</td>\n",
       "      <td>39.074711</td>\n",
       "      <td>39.074715</td>\n",
       "      <td>39.074714</td>\n",
       "      <td>39.074711</td>\n",
       "      <td>39.074708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>233.501222</td>\n",
       "      <td>176.675091</td>\n",
       "      <td>175.834398</td>\n",
       "      <td>197.298105</td>\n",
       "      <td>214.804003</td>\n",
       "      <td>180.737088</td>\n",
       "      <td>227.194120</td>\n",
       "      <td>319.919887</td>\n",
       "      <td>204.767240</td>\n",
       "      <td>194.543116</td>\n",
       "      <td>...</td>\n",
       "      <td>264.368896</td>\n",
       "      <td>246.823425</td>\n",
       "      <td>226.434323</td>\n",
       "      <td>254.694344</td>\n",
       "      <td>299.243361</td>\n",
       "      <td>257.714731</td>\n",
       "      <td>280.107262</td>\n",
       "      <td>288.457868</td>\n",
       "      <td>286.871375</td>\n",
       "      <td>289.329681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.155508</td>\n",
       "      <td>14.347571</td>\n",
       "      <td>11.886017</td>\n",
       "      <td>3.266263</td>\n",
       "      <td>2.324526</td>\n",
       "      <td>8.731954</td>\n",
       "      <td>4.892632</td>\n",
       "      <td>8.215266</td>\n",
       "      <td>6.415149</td>\n",
       "      <td>6.451866</td>\n",
       "      <td>...</td>\n",
       "      <td>2.460711</td>\n",
       "      <td>1.592761</td>\n",
       "      <td>3.455211</td>\n",
       "      <td>5.655280</td>\n",
       "      <td>1.407065</td>\n",
       "      <td>2.099760</td>\n",
       "      <td>3.808670</td>\n",
       "      <td>2.364901</td>\n",
       "      <td>0.768300</td>\n",
       "      <td>2.323814</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>12800.363000</td>\n",
       "      <td>13218.510000</td>\n",
       "      <td>11332.009000</td>\n",
       "      <td>12949.496000</td>\n",
       "      <td>15112.114000</td>\n",
       "      <td>11937.059000</td>\n",
       "      <td>16054.424000</td>\n",
       "      <td>30540.975000</td>\n",
       "      <td>13300.479000</td>\n",
       "      <td>16199.771000</td>\n",
       "      <td>...</td>\n",
       "      <td>16907.543000</td>\n",
       "      <td>15215.647000</td>\n",
       "      <td>15349.081000</td>\n",
       "      <td>17642.918000</td>\n",
       "      <td>22534.312000</td>\n",
       "      <td>16056.861000</td>\n",
       "      <td>24991.297000</td>\n",
       "      <td>24719.457000</td>\n",
       "      <td>17707.127000</td>\n",
       "      <td>18648.555000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 734 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                0             1             2             3             4    \\\n",
       "count  25592.000000  25592.000000  25592.000000  25592.000000  25592.000000   \n",
       "mean      39.074711     39.074714     39.074712     39.074708     39.074708   \n",
       "std      233.501222    176.675091    175.834398    197.298105    214.804003   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        2.155508     14.347571     11.886017      3.266263      2.324526   \n",
       "max    12800.363000  13218.510000  11332.009000  12949.496000  15112.114000   \n",
       "\n",
       "                5             6             7             8             9    \\\n",
       "count  25592.000000  25592.000000  25592.000000  25592.000000  25592.000000   \n",
       "mean      39.074711     39.074712     39.074715     39.074711     39.074710   \n",
       "std      180.737088    227.194120    319.919887    204.767240    194.543116   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        8.731954      4.892632      8.215266      6.415149      6.451866   \n",
       "max    11937.059000  16054.424000  30540.975000  13300.479000  16199.771000   \n",
       "\n",
       "       ...           724           725           726           727  \\\n",
       "count  ...  25592.000000  25592.000000  25592.000000  25592.000000   \n",
       "mean   ...     39.074718     39.074709     39.074713     39.074711   \n",
       "std    ...    264.368896    246.823425    226.434323    254.694344   \n",
       "min    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "25%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "50%    ...      0.000000      0.000000      0.000000      0.000000   \n",
       "75%    ...      2.460711      1.592761      3.455211      5.655280   \n",
       "max    ...  16907.543000  15215.647000  15349.081000  17642.918000   \n",
       "\n",
       "                728           729           730           731           732  \\\n",
       "count  25592.000000  25592.000000  25592.000000  25592.000000  25592.000000   \n",
       "mean      39.074708     39.074711     39.074715     39.074714     39.074711   \n",
       "std      299.243361    257.714731    280.107262    288.457868    286.871375   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        1.407065      2.099760      3.808670      2.364901      0.768300   \n",
       "max    22534.312000  16056.861000  24991.297000  24719.457000  17707.127000   \n",
       "\n",
       "                733  \n",
       "count  25592.000000  \n",
       "mean      39.074708  \n",
       "std      289.329681  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        2.323814  \n",
       "max    18648.555000  \n",
       "\n",
       "[8 rows x 734 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(X_arr).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hRs6748LiXbB"
   },
   "source": [
    "Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "BwNbDW3kMeVl",
    "outputId": "64d53a0e-4231-4c17-c9ad-4ea410f91449"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>724</th>\n",
       "      <th>725</th>\n",
       "      <th>726</th>\n",
       "      <th>727</th>\n",
       "      <th>728</th>\n",
       "      <th>729</th>\n",
       "      <th>730</th>\n",
       "      <th>731</th>\n",
       "      <th>732</th>\n",
       "      <th>733</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.039573</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.029819</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>0.028298</td>\n",
       "      <td>0.044176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 734 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2         3         4         5         6    \\\n",
       "0  0.009735  0.010765  0.097550  0.007142  0.039573  0.039254  0.029819   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.000000  0.011587  0.000000  0.000050  0.004454  0.004185   \n",
       "3  0.000248  0.001442  0.000736  0.000579  0.002009  0.000185  0.000180   \n",
       "4  0.000156  0.000098  0.000539  0.000943  0.009990  0.000189  0.000128   \n",
       "\n",
       "        7         8         9    ...       724       725       726       727  \\\n",
       "0  0.011140  0.028298  0.044176  ...  0.000184  0.000943  0.000000  0.000119   \n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.000000  0.006753  0.005164  ...  0.000000  0.001727  0.000000  0.000000   \n",
       "3  0.000262  0.000876  0.000707  ...  0.000206  0.006726  0.000344  0.000578   \n",
       "4  0.000199  0.006950  0.000070  ...  0.000000  0.010625  0.000228  0.000136   \n",
       "\n",
       "        728       729       730       731       732       733  \n",
       "0  0.000000  0.000463  0.000321  0.000710  0.000077  0.008006  \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000  \n",
       "2  0.000000  0.000065  0.000000  0.000476  0.000000  0.000000  \n",
       "3  0.000126  0.000217  0.006617  0.000183  0.000432  0.000416  \n",
       "4  0.000000  0.005231  0.000087  0.000000  0.000116  0.000000  \n",
       "\n",
       "[5 rows x 734 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "X_arr1=scaler.fit_transform(X_arr)\n",
    "data = pd.DataFrame(X_arr1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YxBfSnAAifCg"
   },
   "source": [
    "Extracting row names and column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E6OU8Ru1MlMW",
    "outputId": "6ae0cb16-ca78-49b9-c52a-fc9df2dfb286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 0                1\n",
      "0  ENSG00000000003  ENSG00000000003\n",
      "1  ENSG00000000005  ENSG00000000005\n",
      "2  ENSG00000000419  ENSG00000000419\n",
      "3  ENSG00000000457  ENSG00000000457\n",
      "4  ENSG00000000460  ENSG00000000460\n",
      "            0\n",
      "0  SRR2967100\n",
      "1  SRR2967101\n",
      "2  SRR2967102\n",
      "3  SRR2967103\n",
      "4  SRR2967104\n"
     ]
    }
   ],
   "source": [
    "row_names = pd.read_csv(dir+'Data/E-GEOD-75140/E-GEOD-75140.aggregated_filtered_normalised_counts.mtx_rows',header=None,sep='\\t')\n",
    "col_names = pd.read_csv(dir+'Data/E-GEOD-75140/E-GEOD-75140.aggregated_filtered_normalised_counts.mtx_cols',header=None,sep='\\t')\n",
    "\n",
    "print(row_names.head())\n",
    "print(col_names.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "OeKbmya7MoeO",
    "outputId": "bf5ba4bc-ff12-431f-ee5e-f2fa0d7cf685"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRR2967100</th>\n",
       "      <th>SRR2967101</th>\n",
       "      <th>SRR2967102</th>\n",
       "      <th>SRR2967103</th>\n",
       "      <th>SRR2967104</th>\n",
       "      <th>SRR2967105</th>\n",
       "      <th>SRR2967106</th>\n",
       "      <th>SRR2967107</th>\n",
       "      <th>SRR2967108</th>\n",
       "      <th>SRR2967109</th>\n",
       "      <th>...</th>\n",
       "      <th>SRR2967824</th>\n",
       "      <th>SRR2967825</th>\n",
       "      <th>SRR2967826</th>\n",
       "      <th>SRR2967827</th>\n",
       "      <th>SRR2967828</th>\n",
       "      <th>SRR2967829</th>\n",
       "      <th>SRR2967830</th>\n",
       "      <th>SRR2967831</th>\n",
       "      <th>SRR2967832</th>\n",
       "      <th>SRR2967833</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.039573</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.029819</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>0.028298</td>\n",
       "      <td>0.044176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 734 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SRR2967100  SRR2967101  SRR2967102  SRR2967103  SRR2967104  \\\n",
       "ENSG00000000003    0.009735    0.010765    0.097550    0.007142    0.039573   \n",
       "ENSG00000000005    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000000419    0.000000    0.000000    0.011587    0.000000    0.000050   \n",
       "ENSG00000000457    0.000248    0.001442    0.000736    0.000579    0.002009   \n",
       "ENSG00000000460    0.000156    0.000098    0.000539    0.000943    0.009990   \n",
       "\n",
       "                 SRR2967105  SRR2967106  SRR2967107  SRR2967108  SRR2967109  \\\n",
       "ENSG00000000003    0.039254    0.029819    0.011140    0.028298    0.044176   \n",
       "ENSG00000000005    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000000419    0.004454    0.004185    0.000000    0.006753    0.005164   \n",
       "ENSG00000000457    0.000185    0.000180    0.000262    0.000876    0.000707   \n",
       "ENSG00000000460    0.000189    0.000128    0.000199    0.006950    0.000070   \n",
       "\n",
       "                 ...  SRR2967824  SRR2967825  SRR2967826  SRR2967827  \\\n",
       "ENSG00000000003  ...    0.000184    0.000943    0.000000    0.000119   \n",
       "ENSG00000000005  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000000419  ...    0.000000    0.001727    0.000000    0.000000   \n",
       "ENSG00000000457  ...    0.000206    0.006726    0.000344    0.000578   \n",
       "ENSG00000000460  ...    0.000000    0.010625    0.000228    0.000136   \n",
       "\n",
       "                 SRR2967828  SRR2967829  SRR2967830  SRR2967831  SRR2967832  \\\n",
       "ENSG00000000003    0.000000    0.000463    0.000321    0.000710    0.000077   \n",
       "ENSG00000000005    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000000419    0.000000    0.000065    0.000000    0.000476    0.000000   \n",
       "ENSG00000000457    0.000126    0.000217    0.006617    0.000183    0.000432   \n",
       "ENSG00000000460    0.000000    0.005231    0.000087    0.000000    0.000116   \n",
       "\n",
       "                 SRR2967833  \n",
       "ENSG00000000003    0.008006  \n",
       "ENSG00000000005    0.000000  \n",
       "ENSG00000000419    0.000000  \n",
       "ENSG00000000457    0.000416  \n",
       "ENSG00000000460    0.000000  \n",
       "\n",
       "[5 rows x 734 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns=list(col_names[0])\n",
    "data.index=list(row_names[0])\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VfItHY-Ikr6q"
   },
   "source": [
    "Removing lowly expressed genes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "e4kovBqzkrmv"
   },
   "outputs": [],
   "source": [
    "length=[]\n",
    "for i in data.index:\n",
    "  gen_val=[]\n",
    "  for j in data.loc[i]:\n",
    "    if j>0:\n",
    "      gen_val.append(j)\n",
    "  length.append(len(gen_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ZEzJXJwVlBA4"
   },
   "outputs": [],
   "source": [
    "amount = [i/data.shape[1] for i in length]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 300
    },
    "id": "jGQ0VXV0lUPo",
    "outputId": "c55a2469-0700-4680-ed0b-9479d60af52f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25592.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.338617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.330210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.004087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.024523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.231608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.628065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0\n",
       "count  25592.000000\n",
       "mean       0.338617\n",
       "std        0.330210\n",
       "min        0.004087\n",
       "25%        0.024523\n",
       "50%        0.231608\n",
       "75%        0.628065\n",
       "max        1.000000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(amount).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "yERxeC55lWsx",
    "outputId": "5c200fdb-ced2-4af4-e1de-35bafaf4242c"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ENSG00000000003</td>\n",
       "      <td>0.798365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ENSG00000000005</td>\n",
       "      <td>0.036785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ENSG00000000419</td>\n",
       "      <td>0.585831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ENSG00000000457</td>\n",
       "      <td>0.854223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ENSG00000000460</td>\n",
       "      <td>0.663488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1\n",
       "0  ENSG00000000003  0.798365\n",
       "1  ENSG00000000005  0.036785\n",
       "2  ENSG00000000419  0.585831\n",
       "3  ENSG00000000457  0.854223\n",
       "4  ENSG00000000460  0.663488"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.DataFrame(data=zip(data.index,amount))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "VoJxZ7yJlp8_"
   },
   "outputs": [],
   "source": [
    "assay=[]\n",
    "cnt=[]\n",
    "for i in range(len(df[1])):\n",
    "  if df[1][i] > df[1].quantile(0.25):\n",
    "    assay.append(df[0][i])\n",
    "    cnt.append(df[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qgTtB8ACly1t",
    "outputId": "c8368204-64a9-410d-8ea0-a3a65040d073"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19037"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(assay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "id": "20WA5foclwJf",
    "outputId": "faf886da-cb61-45aa-df12-0ed5ce2ae471"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SRR2967100</th>\n",
       "      <th>SRR2967101</th>\n",
       "      <th>SRR2967102</th>\n",
       "      <th>SRR2967103</th>\n",
       "      <th>SRR2967104</th>\n",
       "      <th>SRR2967105</th>\n",
       "      <th>SRR2967106</th>\n",
       "      <th>SRR2967107</th>\n",
       "      <th>SRR2967108</th>\n",
       "      <th>SRR2967109</th>\n",
       "      <th>...</th>\n",
       "      <th>SRR2967824</th>\n",
       "      <th>SRR2967825</th>\n",
       "      <th>SRR2967826</th>\n",
       "      <th>SRR2967827</th>\n",
       "      <th>SRR2967828</th>\n",
       "      <th>SRR2967829</th>\n",
       "      <th>SRR2967830</th>\n",
       "      <th>SRR2967831</th>\n",
       "      <th>SRR2967832</th>\n",
       "      <th>SRR2967833</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.039573</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.029819</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>0.028298</td>\n",
       "      <td>0.044176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000288550</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000288556</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000288558</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001315</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000288564</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000288579</th>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.003474</td>\n",
       "      <td>0.001843</td>\n",
       "      <td>0.001042</td>\n",
       "      <td>0.001357</td>\n",
       "      <td>0.003417</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000873</td>\n",
       "      <td>0.001413</td>\n",
       "      <td>0.000108</td>\n",
       "      <td>0.003745</td>\n",
       "      <td>0.000909</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.001080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19037 rows × 734 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 SRR2967100  SRR2967101  SRR2967102  SRR2967103  SRR2967104  \\\n",
       "ENSG00000000003    0.009735    0.010765    0.097550    0.007142    0.039573   \n",
       "ENSG00000000005    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000000419    0.000000    0.000000    0.011587    0.000000    0.000050   \n",
       "ENSG00000000457    0.000248    0.001442    0.000736    0.000579    0.002009   \n",
       "ENSG00000000460    0.000156    0.000098    0.000539    0.000943    0.009990   \n",
       "...                     ...         ...         ...         ...         ...   \n",
       "ENSG00000288550    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000288556    0.000000    0.000339    0.000000    0.000000    0.000000   \n",
       "ENSG00000288558    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000288564    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000288579    0.000078    0.002512    0.003739    0.001887    0.000943   \n",
       "\n",
       "                 SRR2967105  SRR2967106  SRR2967107  SRR2967108  SRR2967109  \\\n",
       "ENSG00000000003    0.039254    0.029819    0.011140    0.028298    0.044176   \n",
       "ENSG00000000005    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000000419    0.004454    0.004185    0.000000    0.006753    0.005164   \n",
       "ENSG00000000457    0.000185    0.000180    0.000262    0.000876    0.000707   \n",
       "ENSG00000000460    0.000189    0.000128    0.000199    0.006950    0.000070   \n",
       "...                     ...         ...         ...         ...         ...   \n",
       "ENSG00000288550    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000288556    0.000000    0.000000    0.000000    0.000000    0.000109   \n",
       "ENSG00000288558    0.000000    0.000000    0.000000    0.000000    0.002067   \n",
       "ENSG00000288564    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000288579    0.003474    0.001843    0.001042    0.001357    0.003417   \n",
       "\n",
       "                 ...  SRR2967824  SRR2967825  SRR2967826  SRR2967827  \\\n",
       "ENSG00000000003  ...    0.000184    0.000943    0.000000    0.000119   \n",
       "ENSG00000000005  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000000419  ...    0.000000    0.001727    0.000000    0.000000   \n",
       "ENSG00000000457  ...    0.000206    0.006726    0.000344    0.000578   \n",
       "ENSG00000000460  ...    0.000000    0.010625    0.000228    0.000136   \n",
       "...              ...         ...         ...         ...         ...   \n",
       "ENSG00000288550  ...    0.000399    0.000000    0.000000    0.000000   \n",
       "ENSG00000288556  ...    0.000000    0.000000    0.000000    0.000067   \n",
       "ENSG00000288558  ...    0.000000    0.000000    0.000000    0.001315   \n",
       "ENSG00000288564  ...    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000288579  ...    0.000873    0.001413    0.000108    0.003745   \n",
       "\n",
       "                 SRR2967828  SRR2967829  SRR2967830  SRR2967831  SRR2967832  \\\n",
       "ENSG00000000003    0.000000    0.000463    0.000321    0.000710    0.000077   \n",
       "ENSG00000000005    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000000419    0.000000    0.000065    0.000000    0.000476    0.000000   \n",
       "ENSG00000000457    0.000126    0.000217    0.006617    0.000183    0.000432   \n",
       "ENSG00000000460    0.000000    0.005231    0.000087    0.000000    0.000116   \n",
       "...                     ...         ...         ...         ...         ...   \n",
       "ENSG00000288550    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000288556    0.000000    0.000000    0.000000    0.000785    0.000000   \n",
       "ENSG00000288558    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000288564    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "ENSG00000288579    0.000909    0.001992    0.001301    0.002405    0.000194   \n",
       "\n",
       "                 SRR2967833  \n",
       "ENSG00000000003    0.008006  \n",
       "ENSG00000000005    0.000000  \n",
       "ENSG00000000419    0.000000  \n",
       "ENSG00000000457    0.000416  \n",
       "ENSG00000000460    0.000000  \n",
       "...                     ...  \n",
       "ENSG00000288550    0.000000  \n",
       "ENSG00000288556    0.000000  \n",
       "ENSG00000288558    0.000000  \n",
       "ENSG00000288564    0.000000  \n",
       "ENSG00000288579    0.001080  \n",
       "\n",
       "[19037 rows x 734 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_data = data.loc[assay]\n",
    "work_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WPN-LSKtimD7"
   },
   "source": [
    "Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 543
    },
    "id": "dO4yD2f9M1pF",
    "outputId": "4cee9194-f053-49fc-aa81-b486daed45e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assay</th>\n",
       "      <th>Sample Characteristic[organism]</th>\n",
       "      <th>Sample Characteristic Ontology Term[organism]</th>\n",
       "      <th>Sample Characteristic[individual]</th>\n",
       "      <th>Sample Characteristic Ontology Term[individual]</th>\n",
       "      <th>Sample Characteristic[age]</th>\n",
       "      <th>Sample Characteristic Ontology Term[age]</th>\n",
       "      <th>Sample Characteristic[developmental stage]</th>\n",
       "      <th>Sample Characteristic Ontology Term[developmental stage]</th>\n",
       "      <th>Sample Characteristic[sex]</th>\n",
       "      <th>...</th>\n",
       "      <th>Factor Value[time]</th>\n",
       "      <th>Factor Value Ontology Term[time]</th>\n",
       "      <th>Factor Value[individual]</th>\n",
       "      <th>Factor Value Ontology Term[individual]</th>\n",
       "      <th>Factor Value[cell type]</th>\n",
       "      <th>Factor Value Ontology Term[cell type]</th>\n",
       "      <th>Factor Value[cell line]</th>\n",
       "      <th>Factor Value Ontology Term[cell line]</th>\n",
       "      <th>Factor Value[sampling site]</th>\n",
       "      <th>Factor Value Ontology Term[sampling site]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR2967100</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>http://purl.obolibrary.org/obo/NCBITaxon_9606</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36 year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adult</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0001272</td>\n",
       "      <td>female</td>\n",
       "      <td>...</td>\n",
       "      <td>33 day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0004905</td>\n",
       "      <td>409B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR2967101</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>http://purl.obolibrary.org/obo/NCBITaxon_9606</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36 year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adult</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0001272</td>\n",
       "      <td>female</td>\n",
       "      <td>...</td>\n",
       "      <td>33 day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0004905</td>\n",
       "      <td>409B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR2967102</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>http://purl.obolibrary.org/obo/NCBITaxon_9606</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36 year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adult</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0001272</td>\n",
       "      <td>female</td>\n",
       "      <td>...</td>\n",
       "      <td>33 day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0004905</td>\n",
       "      <td>409B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR2967103</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>http://purl.obolibrary.org/obo/NCBITaxon_9606</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36 year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adult</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0001272</td>\n",
       "      <td>female</td>\n",
       "      <td>...</td>\n",
       "      <td>33 day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0004905</td>\n",
       "      <td>409B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR2967104</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>http://purl.obolibrary.org/obo/NCBITaxon_9606</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36 year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adult</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0001272</td>\n",
       "      <td>female</td>\n",
       "      <td>...</td>\n",
       "      <td>33 day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>http://www.ebi.ac.uk/efo/EFO_0004905</td>\n",
       "      <td>409B2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Assay Sample Characteristic[organism]  \\\n",
       "0  SRR2967100                    Homo sapiens   \n",
       "1  SRR2967101                    Homo sapiens   \n",
       "2  SRR2967102                    Homo sapiens   \n",
       "3  SRR2967103                    Homo sapiens   \n",
       "4  SRR2967104                    Homo sapiens   \n",
       "\n",
       "   Sample Characteristic Ontology Term[organism]  \\\n",
       "0  http://purl.obolibrary.org/obo/NCBITaxon_9606   \n",
       "1  http://purl.obolibrary.org/obo/NCBITaxon_9606   \n",
       "2  http://purl.obolibrary.org/obo/NCBITaxon_9606   \n",
       "3  http://purl.obolibrary.org/obo/NCBITaxon_9606   \n",
       "4  http://purl.obolibrary.org/obo/NCBITaxon_9606   \n",
       "\n",
       "  Sample Characteristic[individual]  \\\n",
       "0                   iPSC organoid 1   \n",
       "1                   iPSC organoid 1   \n",
       "2                   iPSC organoid 1   \n",
       "3                   iPSC organoid 1   \n",
       "4                   iPSC organoid 1   \n",
       "\n",
       "   Sample Characteristic Ontology Term[individual] Sample Characteristic[age]  \\\n",
       "0                                              NaN                    36 year   \n",
       "1                                              NaN                    36 year   \n",
       "2                                              NaN                    36 year   \n",
       "3                                              NaN                    36 year   \n",
       "4                                              NaN                    36 year   \n",
       "\n",
       "   Sample Characteristic Ontology Term[age]  \\\n",
       "0                                       NaN   \n",
       "1                                       NaN   \n",
       "2                                       NaN   \n",
       "3                                       NaN   \n",
       "4                                       NaN   \n",
       "\n",
       "  Sample Characteristic[developmental stage]  \\\n",
       "0                                      adult   \n",
       "1                                      adult   \n",
       "2                                      adult   \n",
       "3                                      adult   \n",
       "4                                      adult   \n",
       "\n",
       "  Sample Characteristic Ontology Term[developmental stage]  \\\n",
       "0               http://www.ebi.ac.uk/efo/EFO_0001272         \n",
       "1               http://www.ebi.ac.uk/efo/EFO_0001272         \n",
       "2               http://www.ebi.ac.uk/efo/EFO_0001272         \n",
       "3               http://www.ebi.ac.uk/efo/EFO_0001272         \n",
       "4               http://www.ebi.ac.uk/efo/EFO_0001272         \n",
       "\n",
       "  Sample Characteristic[sex]  ... Factor Value[time]  \\\n",
       "0                     female  ...             33 day   \n",
       "1                     female  ...             33 day   \n",
       "2                     female  ...             33 day   \n",
       "3                     female  ...             33 day   \n",
       "4                     female  ...             33 day   \n",
       "\n",
       "  Factor Value Ontology Term[time] Factor Value[individual]  \\\n",
       "0                              NaN          iPSC organoid 1   \n",
       "1                              NaN          iPSC organoid 1   \n",
       "2                              NaN          iPSC organoid 1   \n",
       "3                              NaN          iPSC organoid 1   \n",
       "4                              NaN          iPSC organoid 1   \n",
       "\n",
       "  Factor Value Ontology Term[individual]        Factor Value[cell type]  \\\n",
       "0                                    NaN  induced pluripotent stem cell   \n",
       "1                                    NaN  induced pluripotent stem cell   \n",
       "2                                    NaN  induced pluripotent stem cell   \n",
       "3                                    NaN  induced pluripotent stem cell   \n",
       "4                                    NaN  induced pluripotent stem cell   \n",
       "\n",
       "  Factor Value Ontology Term[cell type] Factor Value[cell line]  \\\n",
       "0  http://www.ebi.ac.uk/efo/EFO_0004905                   409B2   \n",
       "1  http://www.ebi.ac.uk/efo/EFO_0004905                   409B2   \n",
       "2  http://www.ebi.ac.uk/efo/EFO_0004905                   409B2   \n",
       "3  http://www.ebi.ac.uk/efo/EFO_0004905                   409B2   \n",
       "4  http://www.ebi.ac.uk/efo/EFO_0004905                   409B2   \n",
       "\n",
       "  Factor Value Ontology Term[cell line] Factor Value[sampling site]  \\\n",
       "0                                   NaN     whole cerebral organoid   \n",
       "1                                   NaN     whole cerebral organoid   \n",
       "2                                   NaN     whole cerebral organoid   \n",
       "3                                   NaN     whole cerebral organoid   \n",
       "4                                   NaN     whole cerebral organoid   \n",
       "\n",
       "  Factor Value Ontology Term[sampling site]  \n",
       "0                                       NaN  \n",
       "1                                       NaN  \n",
       "2                                       NaN  \n",
       "3                                       NaN  \n",
       "4                                       NaN  \n",
       "\n",
       "[5 rows x 37 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data = pd.read_csv(dir+'Data/E-GEOD-75140/ExpDesign-E-GEOD-75140.tsv', delimiter=\"\\t\")\n",
    "exp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XcISdHqW1kEy",
    "outputId": "206aa7b6-f1b7-4d6f-990e-49e3030d573e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(734, 37)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "d4lpfl4X15d9",
    "outputId": "0565116e-41b9-4a19-c5f1-bca54349110d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Assay', 'Sample Characteristic[organism]',\n",
       "       'Sample Characteristic Ontology Term[organism]',\n",
       "       'Sample Characteristic[individual]',\n",
       "       'Sample Characteristic Ontology Term[individual]',\n",
       "       'Sample Characteristic[age]',\n",
       "       'Sample Characteristic Ontology Term[age]',\n",
       "       'Sample Characteristic[developmental stage]',\n",
       "       'Sample Characteristic Ontology Term[developmental stage]',\n",
       "       'Sample Characteristic[sex]',\n",
       "       'Sample Characteristic Ontology Term[sex]',\n",
       "       'Sample Characteristic[organism part]',\n",
       "       'Sample Characteristic Ontology Term[organism part]',\n",
       "       'Sample Characteristic[progenitor cell type]',\n",
       "       'Sample Characteristic Ontology Term[progenitor cell type]',\n",
       "       'Sample Characteristic[cell type]',\n",
       "       'Sample Characteristic Ontology Term[cell type]',\n",
       "       'Sample Characteristic[cell line]',\n",
       "       'Sample Characteristic Ontology Term[cell line]',\n",
       "       'Sample Characteristic[sampling site]',\n",
       "       'Sample Characteristic Ontology Term[sampling site]',\n",
       "       'Sample Characteristic[growth condition]',\n",
       "       'Sample Characteristic Ontology Term[growth condition]',\n",
       "       'Sample Characteristic[disease]',\n",
       "       'Sample Characteristic Ontology Term[disease]',\n",
       "       'Factor Value[single cell identifier]',\n",
       "       'Factor Value Ontology Term[single cell identifier]',\n",
       "       'Factor Value[time]', 'Factor Value Ontology Term[time]',\n",
       "       'Factor Value[individual]', 'Factor Value Ontology Term[individual]',\n",
       "       'Factor Value[cell type]', 'Factor Value Ontology Term[cell type]',\n",
       "       'Factor Value[cell line]', 'Factor Value Ontology Term[cell line]',\n",
       "       'Factor Value[sampling site]',\n",
       "       'Factor Value Ontology Term[sampling site]'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fc-ayjNPLEKo"
   },
   "source": [
    "Pre-processing the metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "lG0-7svw2RId"
   },
   "outputs": [],
   "source": [
    "exp_data.drop(list(exp_data.filter(regex = 'Sample Characteristic Ontology Term')), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cd0cpeOI2wob",
    "outputId": "45e88fd4-5927-44b9-a471-003484df0406"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Assay', 'Sample Characteristic[organism]',\n",
       "       'Sample Characteristic[individual]', 'Sample Characteristic[age]',\n",
       "       'Sample Characteristic[developmental stage]',\n",
       "       'Sample Characteristic[sex]', 'Sample Characteristic[organism part]',\n",
       "       'Sample Characteristic[progenitor cell type]',\n",
       "       'Sample Characteristic[cell type]', 'Sample Characteristic[cell line]',\n",
       "       'Sample Characteristic[sampling site]',\n",
       "       'Sample Characteristic[growth condition]',\n",
       "       'Sample Characteristic[disease]',\n",
       "       'Factor Value[single cell identifier]',\n",
       "       'Factor Value Ontology Term[single cell identifier]',\n",
       "       'Factor Value[time]', 'Factor Value Ontology Term[time]',\n",
       "       'Factor Value[individual]', 'Factor Value Ontology Term[individual]',\n",
       "       'Factor Value[cell type]', 'Factor Value Ontology Term[cell type]',\n",
       "       'Factor Value[cell line]', 'Factor Value Ontology Term[cell line]',\n",
       "       'Factor Value[sampling site]',\n",
       "       'Factor Value Ontology Term[sampling site]'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "WzInJR783B21"
   },
   "outputs": [],
   "source": [
    "exp_data.drop(list(exp_data.filter(regex = 'Factor Value Ontology Term')), axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZQLwDO5o3Izo",
    "outputId": "938f7d90-0449-490c-e3ad-dd658cc3c61d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Assay', 'Sample Characteristic[organism]',\n",
       "       'Sample Characteristic[individual]', 'Sample Characteristic[age]',\n",
       "       'Sample Characteristic[developmental stage]',\n",
       "       'Sample Characteristic[sex]', 'Sample Characteristic[organism part]',\n",
       "       'Sample Characteristic[progenitor cell type]',\n",
       "       'Sample Characteristic[cell type]', 'Sample Characteristic[cell line]',\n",
       "       'Sample Characteristic[sampling site]',\n",
       "       'Sample Characteristic[growth condition]',\n",
       "       'Sample Characteristic[disease]',\n",
       "       'Factor Value[single cell identifier]', 'Factor Value[time]',\n",
       "       'Factor Value[individual]', 'Factor Value[cell type]',\n",
       "       'Factor Value[cell line]', 'Factor Value[sampling site]'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 783
    },
    "id": "9Nn131R-3WV1",
    "outputId": "fb49bdbf-c757-4cfe-b876-e29c113f1800"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assay</th>\n",
       "      <th>Sample Characteristic[organism]</th>\n",
       "      <th>Sample Characteristic[individual]</th>\n",
       "      <th>Sample Characteristic[age]</th>\n",
       "      <th>Sample Characteristic[developmental stage]</th>\n",
       "      <th>Sample Characteristic[sex]</th>\n",
       "      <th>Sample Characteristic[organism part]</th>\n",
       "      <th>Sample Characteristic[progenitor cell type]</th>\n",
       "      <th>Sample Characteristic[cell type]</th>\n",
       "      <th>Sample Characteristic[cell line]</th>\n",
       "      <th>Sample Characteristic[sampling site]</th>\n",
       "      <th>Sample Characteristic[growth condition]</th>\n",
       "      <th>Sample Characteristic[disease]</th>\n",
       "      <th>Factor Value[single cell identifier]</th>\n",
       "      <th>Factor Value[time]</th>\n",
       "      <th>Factor Value[individual]</th>\n",
       "      <th>Factor Value[cell type]</th>\n",
       "      <th>Factor Value[cell line]</th>\n",
       "      <th>Factor Value[sampling site]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR2967100</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>36 year</td>\n",
       "      <td>adult</td>\n",
       "      <td>female</td>\n",
       "      <td>skin</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>organoid culture</td>\n",
       "      <td>normal</td>\n",
       "      <td>whOrg1_B12_hOrg33d_c2</td>\n",
       "      <td>33 day</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR2967101</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>36 year</td>\n",
       "      <td>adult</td>\n",
       "      <td>female</td>\n",
       "      <td>skin</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>organoid culture</td>\n",
       "      <td>normal</td>\n",
       "      <td>whOrg1_B1_hOrg33d_c2</td>\n",
       "      <td>33 day</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR2967102</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>36 year</td>\n",
       "      <td>adult</td>\n",
       "      <td>female</td>\n",
       "      <td>skin</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>organoid culture</td>\n",
       "      <td>normal</td>\n",
       "      <td>whOrg1_B6_hOrg33d_c2</td>\n",
       "      <td>33 day</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR2967103</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>36 year</td>\n",
       "      <td>adult</td>\n",
       "      <td>female</td>\n",
       "      <td>skin</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>organoid culture</td>\n",
       "      <td>normal</td>\n",
       "      <td>whOrg1_B7_hOrg33d_c2</td>\n",
       "      <td>33 day</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR2967104</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>36 year</td>\n",
       "      <td>adult</td>\n",
       "      <td>female</td>\n",
       "      <td>skin</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>organoid culture</td>\n",
       "      <td>normal</td>\n",
       "      <td>whOrg1_C10_hOrg33d_c2</td>\n",
       "      <td>33 day</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>SRR2967829</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>fetal human cortex 3</td>\n",
       "      <td>gestational week 13 week</td>\n",
       "      <td>embryo</td>\n",
       "      <td>not available</td>\n",
       "      <td>neocortex</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>neuron</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>in vivo</td>\n",
       "      <td>normal</td>\n",
       "      <td>fetal3_H5_fetal_13wpc</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>fetal human cortex 3</td>\n",
       "      <td>neuron</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>SRR2967830</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>fetal human cortex 3</td>\n",
       "      <td>gestational week 13 week</td>\n",
       "      <td>embryo</td>\n",
       "      <td>not available</td>\n",
       "      <td>neocortex</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>neuron</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>in vivo</td>\n",
       "      <td>normal</td>\n",
       "      <td>fetal3_H6_fetal_13wpc</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>fetal human cortex 3</td>\n",
       "      <td>neuron</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>SRR2967831</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>fetal human cortex 3</td>\n",
       "      <td>gestational week 13 week</td>\n",
       "      <td>embryo</td>\n",
       "      <td>not available</td>\n",
       "      <td>neocortex</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>neuron</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>in vivo</td>\n",
       "      <td>normal</td>\n",
       "      <td>fetal3_H7_fetal_13wpc</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>fetal human cortex 3</td>\n",
       "      <td>neuron</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>SRR2967832</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>fetal human cortex 3</td>\n",
       "      <td>gestational week 13 week</td>\n",
       "      <td>embryo</td>\n",
       "      <td>not available</td>\n",
       "      <td>neocortex</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>neuron</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>in vivo</td>\n",
       "      <td>normal</td>\n",
       "      <td>fetal3_H8_fetal_13wpc</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>fetal human cortex 3</td>\n",
       "      <td>neuron</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>SRR2967833</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>fetal human cortex 3</td>\n",
       "      <td>gestational week 13 week</td>\n",
       "      <td>embryo</td>\n",
       "      <td>not available</td>\n",
       "      <td>neocortex</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>neuron</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>in vivo</td>\n",
       "      <td>normal</td>\n",
       "      <td>fetal3_H9_fetal_13wpc</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>fetal human cortex 3</td>\n",
       "      <td>neuron</td>\n",
       "      <td>not applicable</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>734 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Assay Sample Characteristic[organism]  \\\n",
       "0    SRR2967100                    Homo sapiens   \n",
       "1    SRR2967101                    Homo sapiens   \n",
       "2    SRR2967102                    Homo sapiens   \n",
       "3    SRR2967103                    Homo sapiens   \n",
       "4    SRR2967104                    Homo sapiens   \n",
       "..          ...                             ...   \n",
       "729  SRR2967829                    Homo sapiens   \n",
       "730  SRR2967830                    Homo sapiens   \n",
       "731  SRR2967831                    Homo sapiens   \n",
       "732  SRR2967832                    Homo sapiens   \n",
       "733  SRR2967833                    Homo sapiens   \n",
       "\n",
       "    Sample Characteristic[individual] Sample Characteristic[age]  \\\n",
       "0                     iPSC organoid 1                    36 year   \n",
       "1                     iPSC organoid 1                    36 year   \n",
       "2                     iPSC organoid 1                    36 year   \n",
       "3                     iPSC organoid 1                    36 year   \n",
       "4                     iPSC organoid 1                    36 year   \n",
       "..                                ...                        ...   \n",
       "729              fetal human cortex 3   gestational week 13 week   \n",
       "730              fetal human cortex 3   gestational week 13 week   \n",
       "731              fetal human cortex 3   gestational week 13 week   \n",
       "732              fetal human cortex 3   gestational week 13 week   \n",
       "733              fetal human cortex 3   gestational week 13 week   \n",
       "\n",
       "    Sample Characteristic[developmental stage] Sample Characteristic[sex]  \\\n",
       "0                                        adult                     female   \n",
       "1                                        adult                     female   \n",
       "2                                        adult                     female   \n",
       "3                                        adult                     female   \n",
       "4                                        adult                     female   \n",
       "..                                         ...                        ...   \n",
       "729                                     embryo              not available   \n",
       "730                                     embryo              not available   \n",
       "731                                     embryo              not available   \n",
       "732                                     embryo              not available   \n",
       "733                                     embryo              not available   \n",
       "\n",
       "    Sample Characteristic[organism part]  \\\n",
       "0                                   skin   \n",
       "1                                   skin   \n",
       "2                                   skin   \n",
       "3                                   skin   \n",
       "4                                   skin   \n",
       "..                                   ...   \n",
       "729                            neocortex   \n",
       "730                            neocortex   \n",
       "731                            neocortex   \n",
       "732                            neocortex   \n",
       "733                            neocortex   \n",
       "\n",
       "    Sample Characteristic[progenitor cell type]  \\\n",
       "0                                    fibroblast   \n",
       "1                                    fibroblast   \n",
       "2                                    fibroblast   \n",
       "3                                    fibroblast   \n",
       "4                                    fibroblast   \n",
       "..                                          ...   \n",
       "729                              not applicable   \n",
       "730                              not applicable   \n",
       "731                              not applicable   \n",
       "732                              not applicable   \n",
       "733                              not applicable   \n",
       "\n",
       "    Sample Characteristic[cell type] Sample Characteristic[cell line]  \\\n",
       "0      induced pluripotent stem cell                            409B2   \n",
       "1      induced pluripotent stem cell                            409B2   \n",
       "2      induced pluripotent stem cell                            409B2   \n",
       "3      induced pluripotent stem cell                            409B2   \n",
       "4      induced pluripotent stem cell                            409B2   \n",
       "..                               ...                              ...   \n",
       "729                           neuron                   not applicable   \n",
       "730                           neuron                   not applicable   \n",
       "731                           neuron                   not applicable   \n",
       "732                           neuron                   not applicable   \n",
       "733                           neuron                   not applicable   \n",
       "\n",
       "    Sample Characteristic[sampling site]  \\\n",
       "0                whole cerebral organoid   \n",
       "1                whole cerebral organoid   \n",
       "2                whole cerebral organoid   \n",
       "3                whole cerebral organoid   \n",
       "4                whole cerebral organoid   \n",
       "..                                   ...   \n",
       "729                       not applicable   \n",
       "730                       not applicable   \n",
       "731                       not applicable   \n",
       "732                       not applicable   \n",
       "733                       not applicable   \n",
       "\n",
       "    Sample Characteristic[growth condition] Sample Characteristic[disease]  \\\n",
       "0                          organoid culture                         normal   \n",
       "1                          organoid culture                         normal   \n",
       "2                          organoid culture                         normal   \n",
       "3                          organoid culture                         normal   \n",
       "4                          organoid culture                         normal   \n",
       "..                                      ...                            ...   \n",
       "729                                 in vivo                         normal   \n",
       "730                                 in vivo                         normal   \n",
       "731                                 in vivo                         normal   \n",
       "732                                 in vivo                         normal   \n",
       "733                                 in vivo                         normal   \n",
       "\n",
       "    Factor Value[single cell identifier] Factor Value[time]  \\\n",
       "0                  whOrg1_B12_hOrg33d_c2             33 day   \n",
       "1                   whOrg1_B1_hOrg33d_c2             33 day   \n",
       "2                   whOrg1_B6_hOrg33d_c2             33 day   \n",
       "3                   whOrg1_B7_hOrg33d_c2             33 day   \n",
       "4                  whOrg1_C10_hOrg33d_c2             33 day   \n",
       "..                                   ...                ...   \n",
       "729                fetal3_H5_fetal_13wpc     not applicable   \n",
       "730                fetal3_H6_fetal_13wpc     not applicable   \n",
       "731                fetal3_H7_fetal_13wpc     not applicable   \n",
       "732                fetal3_H8_fetal_13wpc     not applicable   \n",
       "733                fetal3_H9_fetal_13wpc     not applicable   \n",
       "\n",
       "    Factor Value[individual]        Factor Value[cell type]  \\\n",
       "0            iPSC organoid 1  induced pluripotent stem cell   \n",
       "1            iPSC organoid 1  induced pluripotent stem cell   \n",
       "2            iPSC organoid 1  induced pluripotent stem cell   \n",
       "3            iPSC organoid 1  induced pluripotent stem cell   \n",
       "4            iPSC organoid 1  induced pluripotent stem cell   \n",
       "..                       ...                            ...   \n",
       "729     fetal human cortex 3                         neuron   \n",
       "730     fetal human cortex 3                         neuron   \n",
       "731     fetal human cortex 3                         neuron   \n",
       "732     fetal human cortex 3                         neuron   \n",
       "733     fetal human cortex 3                         neuron   \n",
       "\n",
       "    Factor Value[cell line] Factor Value[sampling site]  \n",
       "0                     409B2     whole cerebral organoid  \n",
       "1                     409B2     whole cerebral organoid  \n",
       "2                     409B2     whole cerebral organoid  \n",
       "3                     409B2     whole cerebral organoid  \n",
       "4                     409B2     whole cerebral organoid  \n",
       "..                      ...                         ...  \n",
       "729          not applicable              not applicable  \n",
       "730          not applicable              not applicable  \n",
       "731          not applicable              not applicable  \n",
       "732          not applicable              not applicable  \n",
       "733          not applicable              not applicable  \n",
       "\n",
       "[734 rows x 19 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P6Gy5coJ337Q"
   },
   "source": [
    "Removing identical columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HL8DVCKj32y3",
    "outputId": "c29e941c-383d-479e-cee3-c6bed63bdbb7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Assay', 'Sample Characteristic[organism]',\n",
       "       'Sample Characteristic[individual]', 'Sample Characteristic[age]',\n",
       "       'Sample Characteristic[developmental stage]',\n",
       "       'Sample Characteristic[sex]', 'Sample Characteristic[organism part]',\n",
       "       'Sample Characteristic[progenitor cell type]',\n",
       "       'Sample Characteristic[cell type]', 'Sample Characteristic[cell line]',\n",
       "       'Sample Characteristic[sampling site]',\n",
       "       'Sample Characteristic[growth condition]',\n",
       "       'Sample Characteristic[disease]',\n",
       "       'Factor Value[single cell identifier]', 'Factor Value[time]'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data.drop(['Factor Value[individual]','Factor Value[cell type]','Factor Value[sampling site]','Factor Value[cell line]'],axis=1,inplace=True)\n",
    "exp_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jidh61hIjCYU"
   },
   "source": [
    "Renaming the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 461
    },
    "id": "XdQHo_m20S-S",
    "outputId": "18c33393-8c42-49dc-e6c6-6c4009dac5f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Assay</th>\n",
       "      <th>Organism</th>\n",
       "      <th>Individual</th>\n",
       "      <th>Age</th>\n",
       "      <th>Developmental Stage</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Organism Part</th>\n",
       "      <th>Progenitor Cell Type</th>\n",
       "      <th>Cell Type</th>\n",
       "      <th>Cell Line</th>\n",
       "      <th>Sampling Site</th>\n",
       "      <th>Growth Condition</th>\n",
       "      <th>Disease</th>\n",
       "      <th>Single Cell Identifier</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SRR2967100</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>36 year</td>\n",
       "      <td>adult</td>\n",
       "      <td>female</td>\n",
       "      <td>skin</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>organoid culture</td>\n",
       "      <td>normal</td>\n",
       "      <td>whOrg1_B12_hOrg33d_c2</td>\n",
       "      <td>33 day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SRR2967101</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>36 year</td>\n",
       "      <td>adult</td>\n",
       "      <td>female</td>\n",
       "      <td>skin</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>organoid culture</td>\n",
       "      <td>normal</td>\n",
       "      <td>whOrg1_B1_hOrg33d_c2</td>\n",
       "      <td>33 day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SRR2967102</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>36 year</td>\n",
       "      <td>adult</td>\n",
       "      <td>female</td>\n",
       "      <td>skin</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>organoid culture</td>\n",
       "      <td>normal</td>\n",
       "      <td>whOrg1_B6_hOrg33d_c2</td>\n",
       "      <td>33 day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SRR2967103</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>36 year</td>\n",
       "      <td>adult</td>\n",
       "      <td>female</td>\n",
       "      <td>skin</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>organoid culture</td>\n",
       "      <td>normal</td>\n",
       "      <td>whOrg1_B7_hOrg33d_c2</td>\n",
       "      <td>33 day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SRR2967104</td>\n",
       "      <td>Homo sapiens</td>\n",
       "      <td>iPSC organoid 1</td>\n",
       "      <td>36 year</td>\n",
       "      <td>adult</td>\n",
       "      <td>female</td>\n",
       "      <td>skin</td>\n",
       "      <td>fibroblast</td>\n",
       "      <td>induced pluripotent stem cell</td>\n",
       "      <td>409B2</td>\n",
       "      <td>whole cerebral organoid</td>\n",
       "      <td>organoid culture</td>\n",
       "      <td>normal</td>\n",
       "      <td>whOrg1_C10_hOrg33d_c2</td>\n",
       "      <td>33 day</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Assay      Organism       Individual      Age Developmental Stage  \\\n",
       "0  SRR2967100  Homo sapiens  iPSC organoid 1  36 year               adult   \n",
       "1  SRR2967101  Homo sapiens  iPSC organoid 1  36 year               adult   \n",
       "2  SRR2967102  Homo sapiens  iPSC organoid 1  36 year               adult   \n",
       "3  SRR2967103  Homo sapiens  iPSC organoid 1  36 year               adult   \n",
       "4  SRR2967104  Homo sapiens  iPSC organoid 1  36 year               adult   \n",
       "\n",
       "      Sex Organism Part Progenitor Cell Type                      Cell Type  \\\n",
       "0  female          skin           fibroblast  induced pluripotent stem cell   \n",
       "1  female          skin           fibroblast  induced pluripotent stem cell   \n",
       "2  female          skin           fibroblast  induced pluripotent stem cell   \n",
       "3  female          skin           fibroblast  induced pluripotent stem cell   \n",
       "4  female          skin           fibroblast  induced pluripotent stem cell   \n",
       "\n",
       "  Cell Line            Sampling Site  Growth Condition Disease  \\\n",
       "0     409B2  whole cerebral organoid  organoid culture  normal   \n",
       "1     409B2  whole cerebral organoid  organoid culture  normal   \n",
       "2     409B2  whole cerebral organoid  organoid culture  normal   \n",
       "3     409B2  whole cerebral organoid  organoid culture  normal   \n",
       "4     409B2  whole cerebral organoid  organoid culture  normal   \n",
       "\n",
       "  Single Cell Identifier    Time  \n",
       "0  whOrg1_B12_hOrg33d_c2  33 day  \n",
       "1   whOrg1_B1_hOrg33d_c2  33 day  \n",
       "2   whOrg1_B6_hOrg33d_c2  33 day  \n",
       "3   whOrg1_B7_hOrg33d_c2  33 day  \n",
       "4  whOrg1_C10_hOrg33d_c2  33 day  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data.columns = ['Assay','Organism','Individual','Age','Developmental Stage','Sex','Organism Part','Progenitor Cell Type','Cell Type','Cell Line','Sampling Site','Growth Condition','Disease','Single Cell Identifier','Time']\n",
    "exp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0VG4EUc4LLjW",
    "outputId": "be6bd8b3-c7ab-4ea6-90a9-84a6e38b2f38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "not applicable    226\n",
       "53 day             96\n",
       "65 day             80\n",
       "58 day             79\n",
       "41 day             74\n",
       "37 day             71\n",
       "35 day             68\n",
       "33 day             40\n",
       "Name: Time, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data['Time'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BRI7atnGOICy",
    "outputId": "dd650b8d-e03f-4dfe-aa63-23b4702f11af"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "adult         412\n",
       "embryo        226\n",
       "blastocyst     96\n",
       "Name: Developmental Stage, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data['Developmental Stage'].value_counts()\n",
    "\n",
    "#We aim to predict the 226 embryonic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Z4SL_avgOjN-",
    "outputId": "d00abd3d-68ff-4d49-f7b0-4bdacc7125ff"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36 year                     412\n",
       "gestational week 12 week    164\n",
       "not applicable               96\n",
       "gestational week 13 week     62\n",
       "Name: Age, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_data['Age'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BPjBNrYfQHSa",
    "outputId": "c0fdfd96-bfb2-40b2-98c0-5a5040482893"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['not applicable',\n",
       " '53 day',\n",
       " '65 day',\n",
       " '58 day',\n",
       " '41 day',\n",
       " '37 day',\n",
       " '35 day',\n",
       " '33 day']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_points = list(exp_data['Time'].value_counts().index)\n",
    "time_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SVCwetSQV1nC",
    "outputId": "9debe43d-7e81-4f69-a115-3c7d6d6f5a02"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['33 day',\n",
       " '35 day',\n",
       " '37 day',\n",
       " '41 day',\n",
       " '53 day',\n",
       " '58 day',\n",
       " '65 day',\n",
       " 'not applicable']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_points[1],time_points[2] = time_points[2],time_points[1]\n",
    "time_points[2],time_points[3] = time_points[3],time_points[2]\n",
    "time_points = time_points[::-1]\n",
    "time_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "3DhScbfzQx72"
   },
   "outputs": [],
   "source": [
    "merging_data = exp_data[['Assay','Time']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jfD2rjBLnQd"
   },
   "source": [
    "Making the assays, the columns of main data for merging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "ub7UCpHQR4EA",
    "outputId": "cebcfabe-f511-4719-d86a-d08b412ab050"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>ENSG00000001460</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000288380</th>\n",
       "      <th>ENSG00000288525</th>\n",
       "      <th>ENSG00000288529</th>\n",
       "      <th>ENSG00000288534</th>\n",
       "      <th>ENSG00000288550</th>\n",
       "      <th>ENSG00000288556</th>\n",
       "      <th>ENSG00000288558</th>\n",
       "      <th>ENSG00000288564</th>\n",
       "      <th>ENSG00000288579</th>\n",
       "      <th>Assay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SRR2967100</th>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>SRR2967100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR2967101</th>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>SRR2967101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR2967102</th>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>SRR2967102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR2967103</th>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>SRR2967103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SRR2967104</th>\n",
       "      <td>0.039573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>SRR2967104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19038 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            ENSG00000000003  ENSG00000000005  ENSG00000000419  \\\n",
       "SRR2967100         0.009735              0.0         0.000000   \n",
       "SRR2967101         0.010765              0.0         0.000000   \n",
       "SRR2967102         0.097550              0.0         0.011587   \n",
       "SRR2967103         0.007142              0.0         0.000000   \n",
       "SRR2967104         0.039573              0.0         0.000050   \n",
       "\n",
       "            ENSG00000000457  ENSG00000000460  ENSG00000000971  \\\n",
       "SRR2967100         0.000248         0.000156         0.000000   \n",
       "SRR2967101         0.001442         0.000098         0.000085   \n",
       "SRR2967102         0.000736         0.000539         0.000139   \n",
       "SRR2967103         0.000579         0.000943         0.000000   \n",
       "SRR2967104         0.002009         0.009990         0.000000   \n",
       "\n",
       "            ENSG00000001036  ENSG00000001084  ENSG00000001167  \\\n",
       "SRR2967100         0.000078         0.000000         0.000156   \n",
       "SRR2967101         0.000085         0.000303         0.000000   \n",
       "SRR2967102         0.000278         0.000164         0.000208   \n",
       "SRR2967103         0.002105         0.000184         0.000000   \n",
       "SRR2967104         0.000050         0.000000         0.000050   \n",
       "\n",
       "            ENSG00000001460  ...  ENSG00000288380  ENSG00000288525  \\\n",
       "SRR2967100         0.000318  ...         0.000000         0.000078   \n",
       "SRR2967101         0.001015  ...         0.000000         0.000169   \n",
       "SRR2967102         0.000592  ...         0.000081         0.001110   \n",
       "SRR2967103         0.000437  ...         0.000096         0.000000   \n",
       "SRR2967104         0.000000  ...         0.001314         0.000000   \n",
       "\n",
       "            ENSG00000288529  ENSG00000288534  ENSG00000288550  \\\n",
       "SRR2967100              0.0              0.0              0.0   \n",
       "SRR2967101              0.0              0.0              0.0   \n",
       "SRR2967102              0.0              0.0              0.0   \n",
       "SRR2967103              0.0              0.0              0.0   \n",
       "SRR2967104              0.0              0.0              0.0   \n",
       "\n",
       "            ENSG00000288556  ENSG00000288558  ENSG00000288564  \\\n",
       "SRR2967100         0.000000              0.0              0.0   \n",
       "SRR2967101         0.000339              0.0              0.0   \n",
       "SRR2967102         0.000000              0.0              0.0   \n",
       "SRR2967103         0.000000              0.0              0.0   \n",
       "SRR2967104         0.000000              0.0              0.0   \n",
       "\n",
       "            ENSG00000288579       Assay  \n",
       "SRR2967100         0.000078  SRR2967100  \n",
       "SRR2967101         0.002512  SRR2967101  \n",
       "SRR2967102         0.003739  SRR2967102  \n",
       "SRR2967103         0.001887  SRR2967103  \n",
       "SRR2967104         0.000943  SRR2967104  \n",
       "\n",
       "[5 rows x 19038 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transp_data = work_data.T\n",
    "transp_data['Assay'] = transp_data.index\n",
    "transp_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 575
    },
    "id": "WhE6KHh2Q8MF",
    "outputId": "140a2729-2845-44b4-811d-3674c91419ee"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>ENSG00000001460</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000288525</th>\n",
       "      <th>ENSG00000288529</th>\n",
       "      <th>ENSG00000288534</th>\n",
       "      <th>ENSG00000288550</th>\n",
       "      <th>ENSG00000288556</th>\n",
       "      <th>ENSG00000288558</th>\n",
       "      <th>ENSG00000288564</th>\n",
       "      <th>ENSG00000288579</th>\n",
       "      <th>Assay</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>SRR2967100</td>\n",
       "      <td>33 day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002512</td>\n",
       "      <td>SRR2967101</td>\n",
       "      <td>33 day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003739</td>\n",
       "      <td>SRR2967102</td>\n",
       "      <td>33 day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001887</td>\n",
       "      <td>SRR2967103</td>\n",
       "      <td>33 day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>SRR2967104</td>\n",
       "      <td>33 day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.007781</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>SRR2967829</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000528</td>\n",
       "      <td>0.000052</td>\n",
       "      <td>0.000650</td>\n",
       "      <td>0.000601</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001951</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001301</td>\n",
       "      <td>SRR2967830</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>731</th>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.001458</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.001078</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001331</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000785</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>SRR2967831</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>732</th>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000852</td>\n",
       "      <td>0.001006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>SRR2967832</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>0.008006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000665</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001080</td>\n",
       "      <td>SRR2967833</td>\n",
       "      <td>not applicable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>734 rows × 19039 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     ENSG00000000003  ENSG00000000005  ENSG00000000419  ENSG00000000457  \\\n",
       "0           0.009735              0.0         0.000000         0.000248   \n",
       "1           0.010765              0.0         0.000000         0.001442   \n",
       "2           0.097550              0.0         0.011587         0.000736   \n",
       "3           0.007142              0.0         0.000000         0.000579   \n",
       "4           0.039573              0.0         0.000050         0.002009   \n",
       "..               ...              ...              ...              ...   \n",
       "729         0.000463              0.0         0.000065         0.000217   \n",
       "730         0.000321              0.0         0.000000         0.006617   \n",
       "731         0.000710              0.0         0.000476         0.000183   \n",
       "732         0.000077              0.0         0.000000         0.000432   \n",
       "733         0.008006              0.0         0.000000         0.000416   \n",
       "\n",
       "     ENSG00000000460  ENSG00000000971  ENSG00000001036  ENSG00000001084  \\\n",
       "0           0.000156         0.000000         0.000078         0.000000   \n",
       "1           0.000098         0.000085         0.000085         0.000303   \n",
       "2           0.000539         0.000139         0.000278         0.000164   \n",
       "3           0.000943         0.000000         0.002105         0.000184   \n",
       "4           0.009990         0.000000         0.000050         0.000000   \n",
       "..               ...              ...              ...              ...   \n",
       "729         0.005231         0.000000         0.000588         0.000000   \n",
       "730         0.000087         0.000000         0.000528         0.000052   \n",
       "731         0.000000         0.000032         0.001458         0.000270   \n",
       "732         0.000116         0.000039         0.000000         0.000000   \n",
       "733         0.000000         0.000000         0.000665         0.000552   \n",
       "\n",
       "     ENSG00000001167  ENSG00000001460  ...  ENSG00000288525  ENSG00000288529  \\\n",
       "0           0.000156         0.000318  ...         0.000078              0.0   \n",
       "1           0.000000         0.001015  ...         0.000169              0.0   \n",
       "2           0.000208         0.000592  ...         0.001110              0.0   \n",
       "3           0.000000         0.000437  ...         0.000000              0.0   \n",
       "4           0.000050         0.000000  ...         0.000000              0.0   \n",
       "..               ...              ...  ...              ...              ...   \n",
       "729         0.007781         0.000067  ...         0.000000              0.0   \n",
       "730         0.000650         0.000601  ...         0.001951              0.0   \n",
       "731         0.001078         0.000189  ...         0.001331              0.0   \n",
       "732         0.000852         0.001006  ...         0.000194              0.0   \n",
       "733         0.000000         0.001367  ...         0.000000              0.0   \n",
       "\n",
       "     ENSG00000288534  ENSG00000288550  ENSG00000288556  ENSG00000288558  \\\n",
       "0           0.000000              0.0         0.000000              0.0   \n",
       "1           0.000000              0.0         0.000339              0.0   \n",
       "2           0.000000              0.0         0.000000              0.0   \n",
       "3           0.000000              0.0         0.000000              0.0   \n",
       "4           0.000000              0.0         0.000000              0.0   \n",
       "..               ...              ...              ...              ...   \n",
       "729         0.000000              0.0         0.000000              0.0   \n",
       "730         0.000082              0.0         0.000000              0.0   \n",
       "731         0.000000              0.0         0.000785              0.0   \n",
       "732         0.000000              0.0         0.000000              0.0   \n",
       "733         0.000000              0.0         0.000000              0.0   \n",
       "\n",
       "     ENSG00000288564  ENSG00000288579       Assay            Time  \n",
       "0                0.0         0.000078  SRR2967100          33 day  \n",
       "1                0.0         0.002512  SRR2967101          33 day  \n",
       "2                0.0         0.003739  SRR2967102          33 day  \n",
       "3                0.0         0.001887  SRR2967103          33 day  \n",
       "4                0.0         0.000943  SRR2967104          33 day  \n",
       "..               ...              ...         ...             ...  \n",
       "729              0.0         0.001992  SRR2967829  not applicable  \n",
       "730              0.0         0.001301  SRR2967830  not applicable  \n",
       "731              0.0         0.002405  SRR2967831  not applicable  \n",
       "732              0.0         0.000194  SRR2967832  not applicable  \n",
       "733              0.0         0.001080  SRR2967833  not applicable  \n",
       "\n",
       "[734 rows x 19039 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data = pd.merge(transp_data,merging_data,how='right',on='Assay')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 417
    },
    "id": "X0L92r5rTkm4",
    "outputId": "1ebcba99-6dd8-4cb2-f76b-a165bd782586"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <th>ENSG00000000971</th>\n",
       "      <th>ENSG00000001036</th>\n",
       "      <th>ENSG00000001084</th>\n",
       "      <th>ENSG00000001167</th>\n",
       "      <th>ENSG00000001460</th>\n",
       "      <th>...</th>\n",
       "      <th>ENSG00000288349</th>\n",
       "      <th>ENSG00000288380</th>\n",
       "      <th>ENSG00000288525</th>\n",
       "      <th>ENSG00000288529</th>\n",
       "      <th>ENSG00000288534</th>\n",
       "      <th>ENSG00000288550</th>\n",
       "      <th>ENSG00000288556</th>\n",
       "      <th>ENSG00000288558</th>\n",
       "      <th>ENSG00000288564</th>\n",
       "      <th>ENSG00000288579</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33 day</th>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33 day</th>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000169</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000339</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33 day</th>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000139</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.000164</td>\n",
       "      <td>0.000208</td>\n",
       "      <td>0.000592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000081</td>\n",
       "      <td>0.001110</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.003739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33 day</th>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002105</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000096</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33 day</th>\n",
       "      <td>0.039573</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19037 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ENSG00000000003  ENSG00000000005  ENSG00000000419  ENSG00000000457  \\\n",
       "Time                                                                         \n",
       "33 day         0.009735              0.0         0.000000         0.000248   \n",
       "33 day         0.010765              0.0         0.000000         0.001442   \n",
       "33 day         0.097550              0.0         0.011587         0.000736   \n",
       "33 day         0.007142              0.0         0.000000         0.000579   \n",
       "33 day         0.039573              0.0         0.000050         0.002009   \n",
       "\n",
       "        ENSG00000000460  ENSG00000000971  ENSG00000001036  ENSG00000001084  \\\n",
       "Time                                                                         \n",
       "33 day         0.000156         0.000000         0.000078         0.000000   \n",
       "33 day         0.000098         0.000085         0.000085         0.000303   \n",
       "33 day         0.000539         0.000139         0.000278         0.000164   \n",
       "33 day         0.000943         0.000000         0.002105         0.000184   \n",
       "33 day         0.009990         0.000000         0.000050         0.000000   \n",
       "\n",
       "        ENSG00000001167  ENSG00000001460  ...  ENSG00000288349  \\\n",
       "Time                                      ...                    \n",
       "33 day         0.000156         0.000318  ...         0.000000   \n",
       "33 day         0.000000         0.001015  ...         0.000508   \n",
       "33 day         0.000208         0.000592  ...         0.000000   \n",
       "33 day         0.000000         0.000437  ...         0.000000   \n",
       "33 day         0.000050         0.000000  ...         0.000000   \n",
       "\n",
       "        ENSG00000288380  ENSG00000288525  ENSG00000288529  ENSG00000288534  \\\n",
       "Time                                                                         \n",
       "33 day         0.000000         0.000078              0.0              0.0   \n",
       "33 day         0.000000         0.000169              0.0              0.0   \n",
       "33 day         0.000081         0.001110              0.0              0.0   \n",
       "33 day         0.000096         0.000000              0.0              0.0   \n",
       "33 day         0.001314         0.000000              0.0              0.0   \n",
       "\n",
       "        ENSG00000288550  ENSG00000288556  ENSG00000288558  ENSG00000288564  \\\n",
       "Time                                                                         \n",
       "33 day              0.0         0.000000              0.0              0.0   \n",
       "33 day              0.0         0.000339              0.0              0.0   \n",
       "33 day              0.0         0.000000              0.0              0.0   \n",
       "33 day              0.0         0.000000              0.0              0.0   \n",
       "33 day              0.0         0.000000              0.0              0.0   \n",
       "\n",
       "        ENSG00000288579  \n",
       "Time                     \n",
       "33 day         0.000078  \n",
       "33 day         0.002512  \n",
       "33 day         0.003739  \n",
       "33 day         0.001887  \n",
       "33 day         0.000943  \n",
       "\n",
       "[5 rows x 19037 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.index = merged_data['Time']\n",
    "merged_data.drop(['Assay','Time'],axis=1,inplace=True)\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0RsWelBcjOO4"
   },
   "source": [
    "Working data with Genes as rows and Time as columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "J6eP1wYk0gnn",
    "outputId": "7ebd623c-c3d3-44e3-f94c-ad24882382a9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Time</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>...</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.039573</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.029819</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>0.028298</td>\n",
       "      <td>0.044176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 734 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Time               33 day    33 day    33 day    33 day    33 day    33 day  \\\n",
       "ENSG00000000003  0.009735  0.010765  0.097550  0.007142  0.039573  0.039254   \n",
       "ENSG00000000005  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "ENSG00000000419  0.000000  0.000000  0.011587  0.000000  0.000050  0.004454   \n",
       "ENSG00000000457  0.000248  0.001442  0.000736  0.000579  0.002009  0.000185   \n",
       "ENSG00000000460  0.000156  0.000098  0.000539  0.000943  0.009990  0.000189   \n",
       "\n",
       "Time               33 day    33 day    33 day    33 day  ...  not applicable  \\\n",
       "ENSG00000000003  0.029819  0.011140  0.028298  0.044176  ...        0.000184   \n",
       "ENSG00000000005  0.000000  0.000000  0.000000  0.000000  ...        0.000000   \n",
       "ENSG00000000419  0.004185  0.000000  0.006753  0.005164  ...        0.000000   \n",
       "ENSG00000000457  0.000180  0.000262  0.000876  0.000707  ...        0.000206   \n",
       "ENSG00000000460  0.000128  0.000199  0.006950  0.000070  ...        0.000000   \n",
       "\n",
       "Time             not applicable  not applicable  not applicable  \\\n",
       "ENSG00000000003        0.000943        0.000000        0.000119   \n",
       "ENSG00000000005        0.000000        0.000000        0.000000   \n",
       "ENSG00000000419        0.001727        0.000000        0.000000   \n",
       "ENSG00000000457        0.006726        0.000344        0.000578   \n",
       "ENSG00000000460        0.010625        0.000228        0.000136   \n",
       "\n",
       "Time             not applicable  not applicable  not applicable  \\\n",
       "ENSG00000000003        0.000000        0.000463        0.000321   \n",
       "ENSG00000000005        0.000000        0.000000        0.000000   \n",
       "ENSG00000000419        0.000000        0.000065        0.000000   \n",
       "ENSG00000000457        0.000126        0.000217        0.006617   \n",
       "ENSG00000000460        0.000000        0.005231        0.000087   \n",
       "\n",
       "Time             not applicable  not applicable  not applicable  \n",
       "ENSG00000000003        0.000710        0.000077        0.008006  \n",
       "ENSG00000000005        0.000000        0.000000        0.000000  \n",
       "ENSG00000000419        0.000476        0.000000        0.000000  \n",
       "ENSG00000000457        0.000183        0.000432        0.000416  \n",
       "ENSG00000000460        0.000000        0.000116        0.000000  \n",
       "\n",
       "[5 rows x 734 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_data=merged_data.T\n",
    "work_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MJluiK4O5u-O"
   },
   "source": [
    "Checking for Trend-Seasonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 602
    },
    "id": "M4PK9TByAxRk",
    "outputId": "6bba914f-781f-4066-a42b-d49fcf0ce9d7"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#%%script false\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.graphics.tsaplots import plot_acf,plot_pacf\n",
    "plot_acf(work_data.iloc[100])\n",
    "plot_pacf(work_data.iloc[100])\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwT6F3-91bii"
   },
   "source": [
    "Extracting data to be predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "9YRIkrvy4WiJ"
   },
   "outputs": [],
   "source": [
    "X_data = work_data[time_points[:-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "7AGJ7mH94zeT",
    "outputId": "778d765a-bd81-42a2-d177-d5f538c924f8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Time</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>33 day</th>\n",
       "      <th>...</th>\n",
       "      <th>65 day</th>\n",
       "      <th>65 day</th>\n",
       "      <th>65 day</th>\n",
       "      <th>65 day</th>\n",
       "      <th>65 day</th>\n",
       "      <th>65 day</th>\n",
       "      <th>65 day</th>\n",
       "      <th>65 day</th>\n",
       "      <th>65 day</th>\n",
       "      <th>65 day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <td>0.009735</td>\n",
       "      <td>0.010765</td>\n",
       "      <td>0.097550</td>\n",
       "      <td>0.007142</td>\n",
       "      <td>0.039573</td>\n",
       "      <td>0.039254</td>\n",
       "      <td>0.029819</td>\n",
       "      <td>0.011140</td>\n",
       "      <td>0.028298</td>\n",
       "      <td>0.044176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000060</td>\n",
       "      <td>0.000548</td>\n",
       "      <td>0.010269</td>\n",
       "      <td>0.020130</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000648</td>\n",
       "      <td>0.037225</td>\n",
       "      <td>0.036040</td>\n",
       "      <td>0.006841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011587</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.004454</td>\n",
       "      <td>0.004185</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006753</td>\n",
       "      <td>0.005164</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000223</td>\n",
       "      <td>0.029412</td>\n",
       "      <td>0.000112</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.008308</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010195</td>\n",
       "      <td>0.029222</td>\n",
       "      <td>0.016135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.001442</td>\n",
       "      <td>0.000736</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>0.002009</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.000876</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.001663</td>\n",
       "      <td>0.000676</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.000425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000539</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.009990</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.006950</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.001040</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 508 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Time               33 day    33 day    33 day    33 day    33 day    33 day  \\\n",
       "ENSG00000000003  0.009735  0.010765  0.097550  0.007142  0.039573  0.039254   \n",
       "ENSG00000000005  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "ENSG00000000419  0.000000  0.000000  0.011587  0.000000  0.000050  0.004454   \n",
       "ENSG00000000457  0.000248  0.001442  0.000736  0.000579  0.002009  0.000185   \n",
       "ENSG00000000460  0.000156  0.000098  0.000539  0.000943  0.009990  0.000189   \n",
       "\n",
       "Time               33 day    33 day    33 day    33 day  ...    65 day  \\\n",
       "ENSG00000000003  0.029819  0.011140  0.028298  0.044176  ...  0.000060   \n",
       "ENSG00000000005  0.000000  0.000000  0.000000  0.000000  ...  0.000000   \n",
       "ENSG00000000419  0.004185  0.000000  0.006753  0.005164  ...  0.000223   \n",
       "ENSG00000000457  0.000180  0.000262  0.000876  0.000707  ...  0.000280   \n",
       "ENSG00000000460  0.000128  0.000199  0.006950  0.000070  ...  0.000099   \n",
       "\n",
       "Time               65 day    65 day    65 day    65 day    65 day    65 day  \\\n",
       "ENSG00000000003  0.000548  0.010269  0.020130  0.000198  0.000370  0.000648   \n",
       "ENSG00000000005  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
       "ENSG00000000419  0.029412  0.000112  0.000285  0.000298  0.008308  0.000000   \n",
       "ENSG00000000457  0.000281  0.000463  0.001663  0.000676  0.000256  0.000000   \n",
       "ENSG00000000460  0.001040  0.000000  0.000372  0.000080  0.000000  0.000000   \n",
       "\n",
       "Time               65 day    65 day    65 day  \n",
       "ENSG00000000003  0.037225  0.036040  0.006841  \n",
       "ENSG00000000005  0.000000  0.000000  0.000000  \n",
       "ENSG00000000419  0.010195  0.029222  0.016135  \n",
       "ENSG00000000457  0.000000  0.000285  0.000425  \n",
       "ENSG00000000460  0.000000  0.000091  0.000000  \n",
       "\n",
       "[5 rows x 508 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "id": "oD_-SGXN460i",
    "outputId": "b7756175-eec1-491b-d299-bf2b917b9de2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Time</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>...</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "      <th>not applicable</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ENSG00000000003</th>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.000508</td>\n",
       "      <td>0.000293</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000943</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000463</td>\n",
       "      <td>0.000321</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.008006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000005</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000419</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001858</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.006944</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.016598</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001727</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000476</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000457</th>\n",
       "      <td>0.000453</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.00239</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.006726</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>0.000578</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.006617</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000432</td>\n",
       "      <td>0.000416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000000460</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000532</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010625</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.005231</td>\n",
       "      <td>0.000087</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 226 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Time             not applicable  not applicable  not applicable  \\\n",
       "ENSG00000000003        0.000453        0.000155         0.00000   \n",
       "ENSG00000000005        0.000000        0.000000         0.00000   \n",
       "ENSG00000000419        0.000000        0.001858         0.00000   \n",
       "ENSG00000000457        0.000453        0.000198         0.00239   \n",
       "ENSG00000000460        0.000000        0.002633         0.00000   \n",
       "\n",
       "Time             not applicable  not applicable  not applicable  \\\n",
       "ENSG00000000003        0.006944        0.000266        0.000508   \n",
       "ENSG00000000005        0.000000        0.000000        0.000000   \n",
       "ENSG00000000419        0.006944        0.000000        0.001084   \n",
       "ENSG00000000457        0.000000        0.000000        0.000000   \n",
       "ENSG00000000460        0.000000        0.000532        0.000000   \n",
       "\n",
       "Time             not applicable  not applicable  not applicable  \\\n",
       "ENSG00000000003        0.000293             0.0             0.0   \n",
       "ENSG00000000005        0.000000             0.0             0.0   \n",
       "ENSG00000000419        0.000000             0.0             0.0   \n",
       "ENSG00000000457        0.000000             0.0             0.0   \n",
       "ENSG00000000460        0.000000             0.0             0.0   \n",
       "\n",
       "Time             not applicable  ...  not applicable  not applicable  \\\n",
       "ENSG00000000003        0.000000  ...        0.000184        0.000943   \n",
       "ENSG00000000005        0.000000  ...        0.000000        0.000000   \n",
       "ENSG00000000419        0.016598  ...        0.000000        0.001727   \n",
       "ENSG00000000457        0.000000  ...        0.000206        0.006726   \n",
       "ENSG00000000460        0.000494  ...        0.000000        0.010625   \n",
       "\n",
       "Time             not applicable  not applicable  not applicable  \\\n",
       "ENSG00000000003        0.000000        0.000119        0.000000   \n",
       "ENSG00000000005        0.000000        0.000000        0.000000   \n",
       "ENSG00000000419        0.000000        0.000000        0.000000   \n",
       "ENSG00000000457        0.000344        0.000578        0.000126   \n",
       "ENSG00000000460        0.000228        0.000136        0.000000   \n",
       "\n",
       "Time             not applicable  not applicable  not applicable  \\\n",
       "ENSG00000000003        0.000463        0.000321        0.000710   \n",
       "ENSG00000000005        0.000000        0.000000        0.000000   \n",
       "ENSG00000000419        0.000065        0.000000        0.000476   \n",
       "ENSG00000000457        0.000217        0.006617        0.000183   \n",
       "ENSG00000000460        0.005231        0.000087        0.000000   \n",
       "\n",
       "Time             not applicable  not applicable  \n",
       "ENSG00000000003        0.000077        0.008006  \n",
       "ENSG00000000005        0.000000        0.000000  \n",
       "ENSG00000000419        0.000000        0.000000  \n",
       "ENSG00000000457        0.000432        0.000416  \n",
       "ENSG00000000460        0.000116        0.000000  \n",
       "\n",
       "[5 rows x 226 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_data = work_data[time_points[-1]]\n",
    "y_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsWqc-GH5JUa",
    "outputId": "d2d76bf5-6b4b-4c4a-d6c7-65c0be2c4eeb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19037, 508)\n",
      "(19037, 226)\n"
     ]
    }
   ],
   "source": [
    "print(np.shape(X_data))\n",
    "print(np.shape(y_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DSR0JRBt5u-W"
   },
   "source": [
    "# DNN regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "DrpdM2-01TWR"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import keras\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from keras import regularizers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import r2_score\n",
    "import tensorflow as tf\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from sklearn.metrics.pairwise import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.backend.set_floatx('float64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DQUYbYMI5u-X"
   },
   "source": [
    "**Finding the best seed**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "OLmCpvxb5u-Y"
   },
   "outputs": [],
   "source": [
    "def MLP1(x_shape,y_shape):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(350, input_dim=x_shape, kernel_initializer='uniform', activation=\"relu\"))\n",
    "    model.add(Dense(275, kernel_initializer='uniform', activation=\"relu\"))\n",
    "    model.add(Dense(y_shape, kernel_initializer='uniform', activation=\"linear\"))\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xVcu5lby5u-Y",
    "outputId": "4d918052-68d0-4a37-eac8-1a550ddf9297",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Seed = 86\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.5512e-04 - mse: 2.5512e-04 - val_loss: 1.8625e-04 - val_mse: 1.8625e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2119e-04 - mse: 2.2119e-04 - val_loss: 1.5420e-04 - val_mse: 1.5420e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9788e-04 - mse: 1.9788e-04 - val_loss: 1.5330e-04 - val_mse: 1.5330e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.2461e-04 - mse: 3.2461e-04 - val_loss: 1.8087e-04 - val_mse: 1.8087e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1229e-04 - mse: 2.1229e-04 - val_loss: 1.6974e-04 - val_mse: 1.6974e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3535e-04 - mse: 2.3535e-04 - val_loss: 1.9720e-04 - val_mse: 1.9720e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0142e-04 - mse: 2.0142e-04 - val_loss: 7.7281e-04 - val_mse: 7.7281e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0243e-04 - mse: 2.0243e-04 - val_loss: 1.6379e-04 - val_mse: 1.6379e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 3.8317e-04 - mse: 3.8317e-04 - val_loss: 1.9454e-04 - val_mse: 1.9454e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 4s 5ms/step - loss: 2.0367e-04 - mse: 2.0367e-04 - val_loss: 1.7054e-04 - val_mse: 1.7054e-04\n",
      "\n",
      "Seed = 16\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.2846e-04 - mse: 2.2846e-04 - val_loss: 2.1283e-04 - val_mse: 2.1283e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0948e-04 - mse: 2.0948e-04 - val_loss: 2.0424e-04 - val_mse: 2.0424e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.9941e-04 - mse: 1.9941e-04 - val_loss: 1.8931e-04 - val_mse: 1.8931e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0597e-04 - mse: 2.0597e-04 - val_loss: 1.8480e-04 - val_mse: 1.8480e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 4s 5ms/step - loss: 1.8008e-04 - mse: 1.8008e-04 - val_loss: 2.4264e-04 - val_mse: 2.4264e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.7213e-04 - mse: 1.7213e-04 - val_loss: 2.1433e-04 - val_mse: 2.1433e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 4s 5ms/step - loss: 1.7819e-04 - mse: 1.7819e-04 - val_loss: 2.1335e-04 - val_mse: 2.1335e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 4s 5ms/step - loss: 1.7546e-04 - mse: 1.7546e-04 - val_loss: 2.6672e-04 - val_mse: 2.6672e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 4s 5ms/step - loss: 1.8385e-04 - mse: 1.8385e-04 - val_loss: 1.8606e-04 - val_mse: 1.8606e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.6342e-04 - mse: 1.6342e-04 - val_loss: 2.6667e-04 - val_mse: 2.6667e-04\n",
      "\n",
      "Seed = 65\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.1557e-04 - mse: 2.1557e-04 - val_loss: 5.3032e-04 - val_mse: 5.3032e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0444e-04 - mse: 2.0444e-04 - val_loss: 2.0862e-04 - val_mse: 2.0862e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9337e-04 - mse: 1.9337e-04 - val_loss: 3.8665e-04 - val_mse: 3.8665e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.8081e-04 - mse: 1.8081e-04 - val_loss: 2.0853e-04 - val_mse: 2.0853e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.7160e-04 - mse: 1.7160e-04 - val_loss: 1.9225e-04 - val_mse: 1.9225e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 4s 5ms/step - loss: 1.6640e-04 - mse: 1.6640e-04 - val_loss: 2.1618e-04 - val_mse: 2.1618e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0401e-04 - mse: 2.0401e-04 - val_loss: 1.7592e-04 - val_mse: 1.7592e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.6290e-04 - mse: 1.6290e-04 - val_loss: 2.4121e-04 - val_mse: 2.4121e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6240e-04 - mse: 1.6240e-04 - val_loss: 1.8104e-04 - val_mse: 1.8104e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.6461e-04 - mse: 1.6461e-04 - val_loss: 2.4428e-04 - val_mse: 2.4428e-04\n",
      "\n",
      "Seed = 35\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.1491e-04 - mse: 2.1491e-04 - val_loss: 3.0443e-04 - val_mse: 3.0443e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.6754e-04 - mse: 1.6754e-04 - val_loss: 2.5031e-04 - val_mse: 2.5031e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6565e-04 - mse: 1.6565e-04 - val_loss: 2.2379e-04 - val_mse: 2.2379e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.4391e-04 - mse: 1.4391e-04 - val_loss: 2.3419e-04 - val_mse: 2.3419e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.5246e-04 - mse: 1.5246e-04 - val_loss: 4.1268e-04 - val_mse: 4.1268e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.5840e-04 - mse: 1.5840e-04 - val_loss: 2.9872e-04 - val_mse: 2.9872e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.5755e-04 - mse: 1.5755e-04 - val_loss: 2.8956e-04 - val_mse: 2.8956e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.5152e-04 - mse: 1.5152e-04 - val_loss: 4.3479e-04 - val_mse: 4.3479e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8361e-04 - mse: 1.8361e-04 - val_loss: 2.4201e-04 - val_mse: 2.4201e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.5464e-04 - mse: 1.5464e-04 - val_loss: 2.9963e-04 - val_mse: 2.9963e-04\n",
      "\n",
      "Seed = 15\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.5411e-04 - mse: 2.5411e-04 - val_loss: 2.1178e-04 - val_mse: 2.1178e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3406e-04 - mse: 2.3406e-04 - val_loss: 6.0559e-04 - val_mse: 6.0559e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0201e-04 - mse: 2.0201e-04 - val_loss: 1.8203e-04 - val_mse: 1.8203e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0515e-04 - mse: 2.0515e-04 - val_loss: 2.1233e-04 - val_mse: 2.1233e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9543e-04 - mse: 1.9543e-04 - val_loss: 3.2194e-04 - val_mse: 3.2194e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1069e-04 - mse: 2.1069e-04 - val_loss: 2.0639e-04 - val_mse: 2.0639e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0555e-04 - mse: 2.0555e-04 - val_loss: 2.0044e-04 - val_mse: 2.0044e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9053e-04 - mse: 1.9053e-04 - val_loss: 1.8214e-04 - val_mse: 1.8214e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6066e-04 - mse: 1.6066e-04 - val_loss: 1.9456e-04 - val_mse: 1.9456e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8074e-04 - mse: 1.8074e-04 - val_loss: 2.0408e-04 - val_mse: 2.0408e-04\n",
      "\n",
      "Seed = 88\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2604e-04 - mse: 2.2604e-04 - val_loss: 4.3507e-04 - val_mse: 4.3507e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.9652e-04 - mse: 1.9652e-04 - val_loss: 2.5825e-04 - val_mse: 2.5825e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.1572e-04 - mse: 2.1572e-04 - val_loss: 2.0586e-04 - val_mse: 2.0586e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.2515e-04 - mse: 2.2515e-04 - val_loss: 2.3777e-04 - val_mse: 2.3777e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.8671e-04 - mse: 1.8671e-04 - val_loss: 2.0075e-04 - val_mse: 2.0075e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0936e-04 - mse: 2.0936e-04 - val_loss: 2.6407e-04 - val_mse: 2.6407e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0592e-04 - mse: 2.0592e-04 - val_loss: 2.0516e-04 - val_mse: 2.0516e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.8348e-04 - mse: 1.8348e-04 - val_loss: 3.2289e-04 - val_mse: 3.2289e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.8444e-04 - mse: 1.8444e-04 - val_loss: 1.6652e-04 - val_mse: 1.6652e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.7640e-04 - mse: 1.7640e-04 - val_loss: 1.9892e-04 - val_mse: 1.9892e-04\n",
      "\n",
      "Seed = 23\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.6245e-04 - mse: 2.6245e-04 - val_loss: 2.1389e-04 - val_mse: 2.1389e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.3887e-04 - mse: 3.3887e-04 - val_loss: 1.8918e-04 - val_mse: 1.8918e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0319e-04 - mse: 2.0319e-04 - val_loss: 1.8951e-04 - val_mse: 1.8951e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8270e-04 - mse: 1.8270e-04 - val_loss: 1.7304e-04 - val_mse: 1.7304e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8904e-04 - mse: 1.8904e-04 - val_loss: 1.7191e-04 - val_mse: 1.7191e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.7486e-04 - mse: 3.7486e-04 - val_loss: 2.0097e-04 - val_mse: 2.0097e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.9875e-04 - mse: 2.9875e-04 - val_loss: 2.5411e-04 - val_mse: 2.5411e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9793e-04 - mse: 1.9793e-04 - val_loss: 1.9063e-04 - val_mse: 1.9063e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9446e-04 - mse: 1.9446e-04 - val_loss: 2.3917e-04 - val_mse: 2.3917e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.4992e-04 - mse: 2.4992e-04 - val_loss: 1.8313e-04 - val_mse: 1.8313e-04\n",
      "\n",
      "Seed = 58\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.7182e-04 - mse: 2.7182e-04 - val_loss: 1.4602e-04 - val_mse: 1.4602e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.8308e-04 - mse: 2.8308e-04 - val_loss: 1.3105e-04 - val_mse: 1.3105e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0661e-04 - mse: 2.0661e-04 - val_loss: 1.3796e-04 - val_mse: 1.3796e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8654e-04 - mse: 1.8654e-04 - val_loss: 1.8018e-04 - val_mse: 1.8018e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0741e-04 - mse: 2.0741e-04 - val_loss: 1.2952e-04 - val_mse: 1.2952e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2560e-04 - mse: 2.2560e-04 - val_loss: 1.5058e-04 - val_mse: 1.5058e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2477e-04 - mse: 2.2477e-04 - val_loss: 1.2203e-04 - val_mse: 1.2203e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1214e-04 - mse: 2.1214e-04 - val_loss: 1.4423e-04 - val_mse: 1.4423e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9569e-04 - mse: 1.9569e-04 - val_loss: 1.2684e-04 - val_mse: 1.2684e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.7371e-04 - mse: 1.7371e-04 - val_loss: 1.2141e-04 - val_mse: 1.2141e-04\n",
      "\n",
      "Seed = 91\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.0845e-04 - mse: 3.0845e-04 - val_loss: 4.3662e-04 - val_mse: 4.3662e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0100e-04 - mse: 2.0100e-04 - val_loss: 3.9542e-04 - val_mse: 3.9542e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2662e-04 - mse: 2.2662e-04 - val_loss: 3.8085e-04 - val_mse: 3.8085e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.5609e-04 - mse: 2.5609e-04 - val_loss: 4.1487e-04 - val_mse: 4.1487e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3289e-04 - mse: 2.3289e-04 - val_loss: 2.9979e-04 - val_mse: 2.9979e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0438e-04 - mse: 2.0438e-04 - val_loss: 3.0440e-04 - val_mse: 3.0440e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2306e-04 - mse: 2.2306e-04 - val_loss: 3.3448e-04 - val_mse: 3.3448e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0247e-04 - mse: 2.0247e-04 - val_loss: 3.0682e-04 - val_mse: 3.0682e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1122e-04 - mse: 2.1122e-04 - val_loss: 2.7617e-04 - val_mse: 2.7617e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8346e-04 - mse: 1.8346e-04 - val_loss: 3.2027e-04 - val_mse: 3.2027e-04\n",
      "\n",
      "Seed = 56\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0403e-04 - mse: 2.0403e-04 - val_loss: 1.9477e-04 - val_mse: 1.9477e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.7372e-04 - mse: 2.7372e-04 - val_loss: 2.2368e-04 - val_mse: 2.2368e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1053e-04 - mse: 2.1053e-04 - val_loss: 1.8772e-04 - val_mse: 1.8772e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3859e-04 - mse: 2.3859e-04 - val_loss: 3.1747e-04 - val_mse: 3.1747e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3155e-04 - mse: 2.3155e-04 - val_loss: 1.9533e-04 - val_mse: 1.9533e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.4194e-04 - mse: 2.4194e-04 - val_loss: 2.0050e-04 - val_mse: 2.0050e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8336e-04 - mse: 1.8336e-04 - val_loss: 1.9506e-04 - val_mse: 1.9506e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1434e-04 - mse: 2.1434e-04 - val_loss: 1.9907e-04 - val_mse: 1.9907e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0111e-04 - mse: 2.0111e-04 - val_loss: 1.9823e-04 - val_mse: 1.9823e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9449e-04 - mse: 1.9449e-04 - val_loss: 2.0486e-04 - val_mse: 2.0486e-04\n",
      "\n",
      "Seed = 25\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.7258e-04 - mse: 2.7258e-04 - val_loss: 3.4663e-04 - val_mse: 3.4663e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.4232e-04 - mse: 2.4232e-04 - val_loss: 3.7589e-04 - val_mse: 3.7589e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1824e-04 - mse: 2.1824e-04 - val_loss: 3.4080e-04 - val_mse: 3.4080e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9832e-04 - mse: 1.9832e-04 - val_loss: 4.3403e-04 - val_mse: 4.3403e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0095e-04 - mse: 2.0095e-04 - val_loss: 3.2432e-04 - val_mse: 3.2432e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1103e-04 - mse: 2.1103e-04 - val_loss: 3.1746e-04 - val_mse: 3.1746e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.4308e-04 - mse: 2.4308e-04 - val_loss: 4.5881e-04 - val_mse: 4.5881e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3799e-04 - mse: 2.3799e-04 - val_loss: 2.6854e-04 - val_mse: 2.6854e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.8406e-04 - mse: 1.8406e-04 - val_loss: 2.2968e-04 - val_mse: 2.2968e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.8337e-04 - mse: 1.8337e-04 - val_loss: 2.4970e-04 - val_mse: 2.4970e-04\n",
      "\n",
      "Seed = 13\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0639e-04 - mse: 2.0639e-04 - val_loss: 3.3652e-04 - val_mse: 3.3652e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.8827e-04 - mse: 2.8827e-04 - val_loss: 4.5886e-04 - val_mse: 4.5886e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0036e-04 - mse: 2.0036e-04 - val_loss: 2.9137e-04 - val_mse: 2.9137e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0459e-04 - mse: 2.0459e-04 - val_loss: 3.0606e-04 - val_mse: 3.0606e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8655e-04 - mse: 1.8655e-04 - val_loss: 2.7132e-04 - val_mse: 2.7132e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0633e-04 - mse: 2.0633e-04 - val_loss: 2.6614e-04 - val_mse: 2.6614e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6528e-04 - mse: 1.6528e-04 - val_loss: 2.7065e-04 - val_mse: 2.7065e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.6209e-04 - mse: 1.6209e-04 - val_loss: 3.0174e-04 - val_mse: 3.0174e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.8645e-04 - mse: 1.8645e-04 - val_loss: 2.9042e-04 - val_mse: 2.9042e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.7935e-04 - mse: 1.7935e-04 - val_loss: 2.7202e-04 - val_mse: 2.7202e-04\n",
      "\n",
      "Seed = 67\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3372e-04 - mse: 2.3372e-04 - val_loss: 0.0012 - val_mse: 0.0012\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3501e-04 - mse: 2.3501e-04 - val_loss: 5.1401e-04 - val_mse: 5.1401e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9463e-04 - mse: 1.9463e-04 - val_loss: 3.0171e-04 - val_mse: 3.0171e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.9724e-04 - mse: 1.9724e-04 - val_loss: 2.8726e-04 - val_mse: 2.8726e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8609e-04 - mse: 1.8609e-04 - val_loss: 2.7150e-04 - val_mse: 2.7150e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8068e-04 - mse: 1.8068e-04 - val_loss: 2.4365e-04 - val_mse: 2.4365e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6794e-04 - mse: 1.6794e-04 - val_loss: 4.1298e-04 - val_mse: 4.1298e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.4745e-04 - mse: 1.4745e-04 - val_loss: 2.4831e-04 - val_mse: 2.4831e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.4438e-04 - mse: 1.4438e-04 - val_loss: 3.3833e-04 - val_mse: 3.3833e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.6790e-04 - mse: 1.6790e-04 - val_loss: 2.3362e-04 - val_mse: 2.3362e-04\n",
      "\n",
      "Seed = 44\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.7598e-04 - mse: 2.7598e-04 - val_loss: 1.7546e-04 - val_mse: 1.7546e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 7ms/step - loss: 3.2777e-04 - mse: 3.2777e-04 - val_loss: 1.4327e-04 - val_mse: 1.4327e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1077e-04 - mse: 2.1077e-04 - val_loss: 1.5228e-04 - val_mse: 1.5228e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0819e-04 - mse: 2.0819e-04 - val_loss: 2.4568e-04 - val_mse: 2.4568e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9655e-04 - mse: 1.9655e-04 - val_loss: 2.6724e-04 - val_mse: 2.6724e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1252e-04 - mse: 2.1252e-04 - val_loss: 1.5929e-04 - val_mse: 1.5929e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8136e-04 - mse: 1.8136e-04 - val_loss: 1.6907e-04 - val_mse: 1.6907e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.6053e-04 - mse: 2.6053e-04 - val_loss: 2.5481e-04 - val_mse: 2.5481e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0492e-04 - mse: 2.0492e-04 - val_loss: 1.4590e-04 - val_mse: 1.4590e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.4184e-04 - mse: 2.4184e-04 - val_loss: 1.6446e-04 - val_mse: 1.6446e-04\n",
      "\n",
      "Seed = 12\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.4175e-04 - mse: 2.4175e-04 - val_loss: 3.6387e-04 - val_mse: 3.6387e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1460e-04 - mse: 2.1460e-04 - val_loss: 3.2622e-04 - val_mse: 3.2622e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0155e-04 - mse: 2.0155e-04 - val_loss: 3.2618e-04 - val_mse: 3.2618e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0906e-04 - mse: 2.0906e-04 - val_loss: 2.6669e-04 - val_mse: 2.6669e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0568e-04 - mse: 2.0568e-04 - val_loss: 2.9215e-04 - val_mse: 2.9215e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.7153e-04 - mse: 1.7153e-04 - val_loss: 3.5158e-04 - val_mse: 3.5158e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.7401e-04 - mse: 1.7401e-04 - val_loss: 2.3473e-04 - val_mse: 2.3473e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0458e-04 - mse: 2.0458e-04 - val_loss: 3.2312e-04 - val_mse: 3.2312e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3121e-04 - mse: 2.3121e-04 - val_loss: 2.2779e-04 - val_mse: 2.2779e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.2693e-04 - mse: 2.2693e-04 - val_loss: 3.5431e-04 - val_mse: 3.5431e-04\n",
      "\n",
      "Seed = 81\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.0522e-04 - mse: 3.0522e-04 - val_loss: 2.5254e-04 - val_mse: 2.5254e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9761e-04 - mse: 1.9761e-04 - val_loss: 3.6800e-04 - val_mse: 3.6800e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3832e-04 - mse: 2.3832e-04 - val_loss: 2.9545e-04 - val_mse: 2.9545e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0197e-04 - mse: 2.0197e-04 - val_loss: 3.8548e-04 - val_mse: 3.8548e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.4274e-04 - mse: 2.4274e-04 - val_loss: 2.3864e-04 - val_mse: 2.3864e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0465e-04 - mse: 2.0465e-04 - val_loss: 2.3735e-04 - val_mse: 2.3735e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8662e-04 - mse: 1.8662e-04 - val_loss: 3.5814e-04 - val_mse: 3.5814e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0126e-04 - mse: 2.0126e-04 - val_loss: 3.1926e-04 - val_mse: 3.1926e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.5582e-04 - mse: 3.5582e-04 - val_loss: 2.4371e-04 - val_mse: 2.4371e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3380e-04 - mse: 2.3380e-04 - val_loss: 2.3496e-04 - val_mse: 2.3496e-04\n",
      "\n",
      "Seed = 34\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.1428e-04 - mse: 3.1428e-04 - val_loss: 2.4162e-04 - val_mse: 2.4162e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0245e-04 - mse: 2.0245e-04 - val_loss: 3.2539e-04 - val_mse: 3.2539e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2039e-04 - mse: 2.2039e-04 - val_loss: 2.4809e-04 - val_mse: 2.4809e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9851e-04 - mse: 1.9851e-04 - val_loss: 3.1199e-04 - val_mse: 3.1199e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9310e-04 - mse: 1.9310e-04 - val_loss: 6.0908e-04 - val_mse: 6.0908e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.7082e-04 - mse: 1.7082e-04 - val_loss: 4.1683e-04 - val_mse: 4.1683e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.7343e-04 - mse: 1.7343e-04 - val_loss: 2.3446e-04 - val_mse: 2.3446e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6950e-04 - mse: 1.6950e-04 - val_loss: 3.7908e-04 - val_mse: 3.7908e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.7779e-04 - mse: 1.7779e-04 - val_loss: 6.3460e-04 - val_mse: 6.3460e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.5890e-04 - mse: 1.5890e-04 - val_loss: 3.8174e-04 - val_mse: 3.8174e-04\n",
      "\n",
      "Seed = 90\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2296e-04 - mse: 2.2296e-04 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8697e-04 - mse: 1.8697e-04 - val_loss: 3.2496e-04 - val_mse: 3.2496e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0484e-04 - mse: 2.0484e-04 - val_loss: 3.1810e-04 - val_mse: 3.1810e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8052e-04 - mse: 1.8052e-04 - val_loss: 3.2474e-04 - val_mse: 3.2474e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8684e-04 - mse: 1.8684e-04 - val_loss: 3.1240e-04 - val_mse: 3.1240e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6344e-04 - mse: 1.6344e-04 - val_loss: 6.6093e-04 - val_mse: 6.6093e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.5901e-04 - mse: 1.5901e-04 - val_loss: 2.6535e-04 - val_mse: 2.6535e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6727e-04 - mse: 1.6727e-04 - val_loss: 4.2420e-04 - val_mse: 4.2420e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.5091e-04 - mse: 1.5091e-04 - val_loss: 7.2210e-04 - val_mse: 7.2210e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.4184e-04 - mse: 1.4184e-04 - val_loss: 6.7452e-04 - val_mse: 6.7452e-04\n",
      "\n",
      "Seed = 11\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.0130e-04 - mse: 3.0130e-04 - val_loss: 1.5814e-04 - val_mse: 1.5814e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.7986e-04 - mse: 2.7986e-04 - val_loss: 1.4630e-04 - val_mse: 1.4630e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.5431e-04 - mse: 2.5431e-04 - val_loss: 1.3205e-04 - val_mse: 1.3205e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.5624e-04 - mse: 2.5624e-04 - val_loss: 1.3131e-04 - val_mse: 1.3131e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.1241e-04 - mse: 3.1241e-04 - val_loss: 1.3409e-04 - val_mse: 1.3409e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 4.7316e-04 - mse: 4.7316e-04 - val_loss: 1.3524e-04 - val_mse: 1.3524e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.3245e-04 - mse: 3.3245e-04 - val_loss: 1.3625e-04 - val_mse: 1.3625e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.4161e-04 - mse: 2.4161e-04 - val_loss: 1.5110e-04 - val_mse: 1.5110e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2867e-04 - mse: 2.2867e-04 - val_loss: 1.3046e-04 - val_mse: 1.3046e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3471e-04 - mse: 2.3471e-04 - val_loss: 1.3355e-04 - val_mse: 1.3355e-04\n",
      "\n",
      "Seed = 32\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3175e-04 - mse: 2.3175e-04 - val_loss: 2.7135e-04 - val_mse: 2.7135e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0633e-04 - mse: 2.0633e-04 - val_loss: 9.8809e-04 - val_mse: 9.8809e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.4624e-04 - mse: 2.4624e-04 - val_loss: 3.9350e-04 - val_mse: 3.9350e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1108e-04 - mse: 2.1108e-04 - val_loss: 2.5728e-04 - val_mse: 2.5728e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0549e-04 - mse: 2.0549e-04 - val_loss: 4.6121e-04 - val_mse: 4.6121e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0330e-04 - mse: 2.0330e-04 - val_loss: 2.3978e-04 - val_mse: 2.3978e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6313e-04 - mse: 1.6313e-04 - val_loss: 2.9178e-04 - val_mse: 2.9178e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.7008e-04 - mse: 1.7008e-04 - val_loss: 2.8361e-04 - val_mse: 2.8361e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8001e-04 - mse: 1.8001e-04 - val_loss: 3.3684e-04 - val_mse: 3.3684e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.5221e-04 - mse: 2.5221e-04 - val_loss: 3.5209e-04 - val_mse: 3.5209e-04\n"
     ]
    }
   ],
   "source": [
    "rnd_state,r2scores,msescores,maescores,pearsoncorr = [],[],[],[],[]\n",
    "for i in np.random.randint(1,101,20):\n",
    "    print('\\nSeed = {}'.format(i))\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size = 0.2,shuffle=True,random_state=i)\n",
    "    model = MLP1(np.shape(X_train)[1],np.shape(y_train)[1])\n",
    "    model.fit(np.array(X_train), np.array(y_train), epochs=10, batch_size=16, validation_split=0.2, shuffle=True)\n",
    "    y_pred = model.predict(np.array(X_test))\n",
    "    \n",
    "    #results\n",
    "    rnd_state.append(i)\n",
    "    \n",
    "    actual_mean = pd.DataFrame(y_test.mean(axis=1))\n",
    "    pred_mean = pd.DataFrame(y_pred.mean(axis=1))\n",
    "    r2scores.append(r2_score(actual_mean, pred_mean))\n",
    "    msescores.append(mean_squared_error(np.array(y_test), y_pred))\n",
    "    maescores.append(mean_absolute_error(np.array(y_test), y_pred))\n",
    "    \n",
    "    dist_orig = np.square(euclidean_distances(y_test, y_test)).flatten()\n",
    "    dist_pred = np.square(euclidean_distances(y_pred, y_pred)).flatten()\n",
    "    corr, _ = pearsonr(dist_orig, dist_pred)\n",
    "    pearsoncorr.append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 707
    },
    "id": "2ePntufW5u-i",
    "outputId": "c58e5bd8-1727-4fc5-916b-4fb0c1ceddeb"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Seed</th>\n",
       "      <th>R2Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Correlation Coeff.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>86.0</td>\n",
       "      <td>0.790822</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.004284</td>\n",
       "      <td>0.883099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.0</td>\n",
       "      <td>0.544396</td>\n",
       "      <td>0.000331</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>0.860709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0.950674</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.004055</td>\n",
       "      <td>0.949589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>0.800703</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.004560</td>\n",
       "      <td>0.676159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.916553</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.974744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>88.0</td>\n",
       "      <td>0.355957</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.549745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>23.0</td>\n",
       "      <td>0.937803</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0.003626</td>\n",
       "      <td>0.954562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>58.0</td>\n",
       "      <td>0.885758</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.004326</td>\n",
       "      <td>0.950333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>91.0</td>\n",
       "      <td>0.744273</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>0.003817</td>\n",
       "      <td>0.821110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>56.0</td>\n",
       "      <td>0.615610</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.742342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.831428</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.003664</td>\n",
       "      <td>0.973543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>13.0</td>\n",
       "      <td>0.906438</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.932128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>67.0</td>\n",
       "      <td>0.868815</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.003727</td>\n",
       "      <td>0.985713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>44.0</td>\n",
       "      <td>0.861979</td>\n",
       "      <td>0.000262</td>\n",
       "      <td>0.004192</td>\n",
       "      <td>0.959805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>12.0</td>\n",
       "      <td>0.509202</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.693959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>81.0</td>\n",
       "      <td>0.923508</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.991931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>34.0</td>\n",
       "      <td>0.856862</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.003776</td>\n",
       "      <td>0.881997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>90.0</td>\n",
       "      <td>0.722793</td>\n",
       "      <td>0.000161</td>\n",
       "      <td>0.004139</td>\n",
       "      <td>0.871773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.664739</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>0.003651</td>\n",
       "      <td>0.863595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>32.0</td>\n",
       "      <td>0.833485</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.003893</td>\n",
       "      <td>0.954738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>47.1</td>\n",
       "      <td>0.776090</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>0.873579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Seed   R2Score       MSE       MAE  Correlation Coeff.\n",
       "0    86.0  0.790822  0.000200  0.004284            0.883099\n",
       "1    16.0  0.544396  0.000331  0.004035            0.860709\n",
       "2    65.0  0.950674  0.000206  0.004055            0.949589\n",
       "3    35.0  0.800703  0.000273  0.004560            0.676159\n",
       "4    15.0  0.916553  0.000145  0.003656            0.974744\n",
       "5    88.0  0.355957  0.000297  0.004545            0.549745\n",
       "6    23.0  0.937803  0.000143  0.003626            0.954562\n",
       "7    58.0  0.885758  0.000207  0.004326            0.950333\n",
       "8    91.0  0.744273  0.000153  0.003817            0.821110\n",
       "9    56.0  0.615610  0.000248  0.003909            0.742342\n",
       "10   25.0  0.831428  0.000137  0.003664            0.973543\n",
       "11   13.0  0.906438  0.000194  0.003931            0.932128\n",
       "12   67.0  0.868815  0.000162  0.003727            0.985713\n",
       "13   44.0  0.861979  0.000262  0.004192            0.959805\n",
       "14   12.0  0.509202  0.000218  0.005556            0.693959\n",
       "15   81.0  0.923508  0.000179  0.004348            0.991931\n",
       "16   34.0  0.856862  0.000184  0.003776            0.881997\n",
       "17   90.0  0.722793  0.000161  0.004139            0.871773\n",
       "18   11.0  0.664739  0.000116  0.003651            0.863595\n",
       "19   32.0  0.833485  0.000151  0.003893            0.954738\n",
       "avg  47.1  0.776090  0.000198  0.004084            0.873579"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(zip(rnd_state,r2scores,msescores,maescores,pearsoncorr))\n",
    "result.columns = ['Seed','R2Score','MSE','MAE','Correlation Coeff.']\n",
    "result.loc[len(rnd_state)] = result.mean(numeric_only=True, axis=0)\n",
    "result.rename(index={len(rnd_state):'avg'},inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "4BpzVYFv5u-j"
   },
   "outputs": [],
   "source": [
    "result.to_csv(dir+'Results/EGEOD75140/bestSeed.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J9eVsBWa8qI4"
   },
   "source": [
    "Extracting results with repeated runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p91riOmJ_sqW"
   },
   "source": [
    "**DNN with no dropout**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9-N-ZScz8xKA",
    "outputId": "061046d8-4ff8-4628-cefa-2c54b186c452"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run = 1\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.7054e-04 - mse: 2.7054e-04 - val_loss: 2.5842e-04 - val_mse: 2.5842e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0840e-04 - mse: 2.0840e-04 - val_loss: 3.5238e-04 - val_mse: 3.5238e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.2263e-04 - mse: 2.2263e-04 - val_loss: 2.9559e-04 - val_mse: 2.9559e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.8585e-04 - mse: 1.8585e-04 - val_loss: 2.1957e-04 - val_mse: 2.1957e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.1479e-04 - mse: 2.1479e-04 - val_loss: 2.7276e-04 - val_mse: 2.7276e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.9936e-04 - mse: 1.9936e-04 - val_loss: 2.2504e-04 - val_mse: 2.2504e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.7627e-04 - mse: 1.7627e-04 - val_loss: 3.8316e-04 - val_mse: 3.8316e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1628e-04 - mse: 2.1628e-04 - val_loss: 3.4636e-04 - val_mse: 3.4636e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3157e-04 - mse: 2.3157e-04 - val_loss: 3.1626e-04 - val_mse: 3.1626e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1962e-04 - mse: 2.1962e-04 - val_loss: 2.5283e-04 - val_mse: 2.5283e-04\n",
      "\n",
      "Run = 2\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.5047e-04 - mse: 3.5047e-04 - val_loss: 2.7258e-04 - val_mse: 2.7258e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8933e-04 - mse: 1.8933e-04 - val_loss: 3.0159e-04 - val_mse: 3.0159e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3469e-04 - mse: 2.3469e-04 - val_loss: 2.6392e-04 - val_mse: 2.6392e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.7767e-04 - mse: 1.7767e-04 - val_loss: 2.5357e-04 - val_mse: 2.5357e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.8196e-04 - mse: 2.8196e-04 - val_loss: 3.0242e-04 - val_mse: 3.0242e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9116e-04 - mse: 1.9116e-04 - val_loss: 2.2723e-04 - val_mse: 2.2723e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.7908e-04 - mse: 1.7908e-04 - val_loss: 3.2366e-04 - val_mse: 3.2366e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.7744e-04 - mse: 1.7744e-04 - val_loss: 6.6630e-04 - val_mse: 6.6630e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0784e-04 - mse: 2.0784e-04 - val_loss: 2.4242e-04 - val_mse: 2.4242e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1261e-04 - mse: 2.1261e-04 - val_loss: 2.3619e-04 - val_mse: 2.3619e-04\n",
      "\n",
      "Run = 3\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.8491e-04 - mse: 2.8491e-04 - val_loss: 2.9647e-04 - val_mse: 2.9647e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2581e-04 - mse: 2.2581e-04 - val_loss: 2.9678e-04 - val_mse: 2.9678e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0869e-04 - mse: 2.0869e-04 - val_loss: 2.9589e-04 - val_mse: 2.9589e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1495e-04 - mse: 2.1495e-04 - val_loss: 3.0911e-04 - val_mse: 3.0911e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.9648e-04 - mse: 1.9648e-04 - val_loss: 2.3692e-04 - val_mse: 2.3692e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.9608e-04 - mse: 1.9608e-04 - val_loss: 2.5983e-04 - val_mse: 2.5983e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3012e-04 - mse: 2.3012e-04 - val_loss: 4.3665e-04 - val_mse: 4.3665e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3166e-04 - mse: 2.3166e-04 - val_loss: 2.9283e-04 - val_mse: 2.9283e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.5154e-04 - mse: 2.5154e-04 - val_loss: 3.1398e-04 - val_mse: 3.1398e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2541e-04 - mse: 2.2541e-04 - val_loss: 2.7523e-04 - val_mse: 2.7523e-04\n",
      "\n",
      "Run = 4\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.9579e-04 - mse: 2.9579e-04 - val_loss: 2.3582e-04 - val_mse: 2.3582e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1347e-04 - mse: 2.1347e-04 - val_loss: 3.0259e-04 - val_mse: 3.0259e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2913e-04 - mse: 2.2913e-04 - val_loss: 3.0712e-04 - val_mse: 3.0712e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1172e-04 - mse: 2.1172e-04 - val_loss: 2.8645e-04 - val_mse: 2.8645e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9558e-04 - mse: 1.9558e-04 - val_loss: 2.6480e-04 - val_mse: 2.6480e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1401e-04 - mse: 2.1401e-04 - val_loss: 2.3070e-04 - val_mse: 2.3070e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8208e-04 - mse: 1.8208e-04 - val_loss: 2.3607e-04 - val_mse: 2.3607e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.7207e-04 - mse: 1.7207e-04 - val_loss: 8.1998e-04 - val_mse: 8.1998e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 6.5253e-04 - mse: 6.5253e-04 - val_loss: 2.7703e-04 - val_mse: 2.7703e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.2211e-04 - mse: 2.2211e-04 - val_loss: 2.4852e-04 - val_mse: 2.4852e-04\n",
      "\n",
      "Run = 5\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.7413e-04 - mse: 2.7413e-04 - val_loss: 2.6753e-04 - val_mse: 2.6753e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.8590e-04 - mse: 1.8590e-04 - val_loss: 3.4916e-04 - val_mse: 3.4916e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.2878e-04 - mse: 2.2878e-04 - val_loss: 3.0711e-04 - val_mse: 3.0711e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0008e-04 - mse: 2.0008e-04 - val_loss: 3.1384e-04 - val_mse: 3.1384e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.7851e-04 - mse: 1.7851e-04 - val_loss: 2.3928e-04 - val_mse: 2.3928e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.6557e-04 - mse: 2.6557e-04 - val_loss: 2.6342e-04 - val_mse: 2.6342e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.0116e-04 - mse: 2.0116e-04 - val_loss: 2.2988e-04 - val_mse: 2.2988e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.7422e-04 - mse: 1.7422e-04 - val_loss: 4.6918e-04 - val_mse: 4.6918e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.5409e-04 - mse: 1.5409e-04 - val_loss: 4.5222e-04 - val_mse: 4.5222e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.1974e-04 - mse: 2.1974e-04 - val_loss: 2.4813e-04 - val_mse: 2.4813e-04\n",
      "\n",
      "Run = 6\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.7926e-04 - mse: 2.7926e-04 - val_loss: 2.3585e-04 - val_mse: 2.3585e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1082e-04 - mse: 2.1082e-04 - val_loss: 2.9231e-04 - val_mse: 2.9231e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1283e-04 - mse: 2.1283e-04 - val_loss: 3.0387e-04 - val_mse: 3.0387e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 3.2395e-04 - mse: 3.2395e-04 - val_loss: 3.9632e-04 - val_mse: 3.9632e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3856e-04 - mse: 2.3856e-04 - val_loss: 2.8216e-04 - val_mse: 2.8216e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1302e-04 - mse: 2.1302e-04 - val_loss: 2.1190e-04 - val_mse: 2.1190e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8031e-04 - mse: 1.8031e-04 - val_loss: 3.0886e-04 - val_mse: 3.0886e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0278e-04 - mse: 2.0278e-04 - val_loss: 2.4545e-04 - val_mse: 2.4545e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9347e-04 - mse: 1.9347e-04 - val_loss: 2.4578e-04 - val_mse: 2.4578e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1928e-04 - mse: 2.1928e-04 - val_loss: 3.0612e-04 - val_mse: 3.0612e-04\n",
      "\n",
      "Run = 7\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3999e-04 - mse: 2.3999e-04 - val_loss: 2.5059e-04 - val_mse: 2.5059e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9527e-04 - mse: 1.9527e-04 - val_loss: 3.3687e-04 - val_mse: 3.3687e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.5417e-04 - mse: 2.5417e-04 - val_loss: 2.8082e-04 - val_mse: 2.8082e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9902e-04 - mse: 1.9902e-04 - val_loss: 2.3220e-04 - val_mse: 2.3220e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6851e-04 - mse: 1.6851e-04 - val_loss: 4.1993e-04 - val_mse: 4.1993e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3811e-04 - mse: 2.3811e-04 - val_loss: 2.3495e-04 - val_mse: 2.3495e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8252e-04 - mse: 1.8252e-04 - val_loss: 2.2212e-04 - val_mse: 2.2212e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1575e-04 - mse: 2.1575e-04 - val_loss: 3.9288e-04 - val_mse: 3.9288e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6505e-04 - mse: 1.6505e-04 - val_loss: 2.5733e-04 - val_mse: 2.5733e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.2255e-04 - mse: 2.2255e-04 - val_loss: 2.4080e-04 - val_mse: 2.4080e-04\n",
      "\n",
      "Run = 8\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.3956e-04 - mse: 3.3956e-04 - val_loss: 3.4164e-04 - val_mse: 3.4164e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1696e-04 - mse: 2.1696e-04 - val_loss: 2.8337e-04 - val_mse: 2.8337e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.4052e-04 - mse: 2.4052e-04 - val_loss: 3.1921e-04 - val_mse: 3.1921e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8390e-04 - mse: 1.8390e-04 - val_loss: 2.8883e-04 - val_mse: 2.8883e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9113e-04 - mse: 1.9113e-04 - val_loss: 2.5758e-04 - val_mse: 2.5758e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0302e-04 - mse: 2.0302e-04 - val_loss: 2.2475e-04 - val_mse: 2.2475e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.7981e-04 - mse: 1.7981e-04 - val_loss: 2.6947e-04 - val_mse: 2.6947e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0179e-04 - mse: 2.0179e-04 - val_loss: 3.7150e-04 - val_mse: 3.7150e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6512e-04 - mse: 1.6512e-04 - val_loss: 2.6512e-04 - val_mse: 2.6512e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0190e-04 - mse: 2.0190e-04 - val_loss: 2.5443e-04 - val_mse: 2.5443e-04\n",
      "\n",
      "Run = 9\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.9308e-04 - mse: 2.9308e-04 - val_loss: 3.0193e-04 - val_mse: 3.0193e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0257e-04 - mse: 2.0257e-04 - val_loss: 2.8908e-04 - val_mse: 2.8908e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.0058e-04 - mse: 2.0058e-04 - val_loss: 2.5369e-04 - val_mse: 2.5369e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6792e-04 - mse: 1.6792e-04 - val_loss: 2.6773e-04 - val_mse: 2.6773e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3138e-04 - mse: 2.3138e-04 - val_loss: 2.8578e-04 - val_mse: 2.8578e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.3723e-04 - mse: 2.3723e-04 - val_loss: 2.4110e-04 - val_mse: 2.4110e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.1947e-04 - mse: 2.1947e-04 - val_loss: 3.0899e-04 - val_mse: 3.0899e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 3.3862e-04 - mse: 3.3862e-04 - val_loss: 4.6514e-04 - val_mse: 4.6514e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.4334e-04 - mse: 2.4334e-04 - val_loss: 2.9239e-04 - val_mse: 2.9239e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.9930e-04 - mse: 1.9930e-04 - val_loss: 2.8789e-04 - val_mse: 2.8789e-04\n",
      "\n",
      "Run = 10\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.5852e-04 - mse: 2.5852e-04 - val_loss: 3.0816e-04 - val_mse: 3.0816e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.8224e-04 - mse: 1.8224e-04 - val_loss: 3.2121e-04 - val_mse: 3.2121e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 2.4892e-04 - mse: 2.4892e-04 - val_loss: 2.9488e-04 - val_mse: 2.9488e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.1277e-04 - mse: 2.1277e-04 - val_loss: 2.7290e-04 - val_mse: 2.7290e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.8481e-04 - mse: 1.8481e-04 - val_loss: 4.2098e-04 - val_mse: 4.2098e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 5.0925e-04 - mse: 5.0925e-04 - val_loss: 2.6147e-04 - val_mse: 2.6147e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.2565e-04 - mse: 2.2565e-04 - val_loss: 2.7495e-04 - val_mse: 2.7495e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 2.1097e-04 - mse: 2.1097e-04 - val_loss: 3.1942e-04 - val_mse: 3.1942e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 4s 6ms/step - loss: 1.7378e-04 - mse: 1.7378e-04 - val_loss: 2.1577e-04 - val_mse: 2.1577e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 5s 6ms/step - loss: 1.6576e-04 - mse: 1.6576e-04 - val_loss: 2.4946e-04 - val_mse: 2.4946e-04\n"
     ]
    }
   ],
   "source": [
    "run,r2scores,msescores,maescores,pearsoncorr = [],[],[],[],[]\n",
    "for i in range(10):\n",
    "    print('\\nRun = {}'.format(i+1))\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size = 0.2,shuffle=True,random_state=81)\n",
    "    model = MLP1(np.shape(X_train)[1],np.shape(y_train)[1])\n",
    "    model.fit(np.array(X_train), np.array(y_train), epochs=10, batch_size=16, validation_split=0.2, shuffle=True)\n",
    "    y_pred = model.predict(np.array(X_test))\n",
    "    \n",
    "    #results\n",
    "    run.append(i+1)\n",
    "    \n",
    "    actual_mean = pd.DataFrame(y_test.mean(axis=1))\n",
    "    pred_mean = pd.DataFrame(y_pred.mean(axis=1))\n",
    "    r2scores.append(r2_score(actual_mean, pred_mean))\n",
    "    msescores.append(mean_squared_error(np.array(y_test), y_pred))\n",
    "    maescores.append(mean_absolute_error(np.array(y_test), y_pred))\n",
    "    \n",
    "    dist_orig = np.square(euclidean_distances(y_test, y_test)).flatten()\n",
    "    dist_pred = np.square(euclidean_distances(y_pred, y_pred)).flatten()\n",
    "    corr, _ = pearsonr(dist_orig, dist_pred)\n",
    "    pearsoncorr.append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "WFuUPQUA8xtD",
    "outputId": "32e36a92-7686-43cb-ddf5-3599e0df6018"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Run</th>\n",
       "      <th>R2Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Correlation Coeff.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.838286</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.004191</td>\n",
       "      <td>0.986082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.795157</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>0.987857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.875038</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.004179</td>\n",
       "      <td>0.988235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.929647</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.004481</td>\n",
       "      <td>0.987123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.920734</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.004150</td>\n",
       "      <td>0.994868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.751889</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.004338</td>\n",
       "      <td>0.918369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.900921</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.985436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.869561</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>0.988803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.751777</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.005901</td>\n",
       "      <td>0.984710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.945027</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.004143</td>\n",
       "      <td>0.992090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.857804</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.004470</td>\n",
       "      <td>0.981357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     #Run   R2Score       MSE       MAE  Correlation Coeff.\n",
       "0     1.0  0.838286  0.000189  0.004191            0.986082\n",
       "1     2.0  0.795157  0.000217  0.004298            0.987857\n",
       "2     3.0  0.875038  0.000180  0.004179            0.988235\n",
       "3     4.0  0.929647  0.000177  0.004481            0.987123\n",
       "4     5.0  0.920734  0.000175  0.004150            0.994868\n",
       "5     6.0  0.751889  0.000211  0.004338            0.918369\n",
       "6     7.0  0.900921  0.000189  0.004945            0.985436\n",
       "7     8.0  0.869561  0.000184  0.004075            0.988803\n",
       "8     9.0  0.751777  0.000209  0.005901            0.984710\n",
       "9    10.0  0.945027  0.000166  0.004143            0.992090\n",
       "avg   5.5  0.857804  0.000190  0.004470            0.981357"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(zip(run,r2scores,msescores,maescores,pearsoncorr))\n",
    "result.columns = ['#Run','R2Score','MSE','MAE','Correlation Coeff.']\n",
    "result.loc[len(run)] = result.mean(numeric_only=True, axis=0)\n",
    "result.rename(index={len(run):'avg'},inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "AQO0Jbhe-RES"
   },
   "outputs": [],
   "source": [
    "result.to_csv(dir+'Results/EGEOD75140/DNN_noDropout_10runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 696
    },
    "id": "YcXS5oNo-RKA",
    "outputId": "a1864bea-460e-45d7-c56a-4effacad7420"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_29\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_87 (Dense)             (None, 350)               178150    \n",
      "_________________________________________________________________\n",
      "dense_88 (Dense)             (None, 275)               96525     \n",
      "_________________________________________________________________\n",
      "dense_89 (Dense)             (None, 226)               62376     \n",
      "=================================================================\n",
      "Total params: 337,051\n",
      "Trainable params: 337,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dYZgE-OO5u-n"
   },
   "source": [
    "**DNN with 10% dropout all all layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "LxwYFii15u-n"
   },
   "outputs": [],
   "source": [
    "def MLP2(x_shape,y_shape,rnd):\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.1,seed=rnd))\n",
    "    model.add(Dense(350, input_dim=x_shape, kernel_initializer='uniform', activation=\"relu\"))\n",
    "    model.add(Dropout(0.1,seed=rnd))\n",
    "    model.add(Dense(275, kernel_initializer='uniform', activation=\"relu\"))\n",
    "    model.add(Dropout(0.1,seed=rnd))\n",
    "    model.add(Dense(y_shape, kernel_initializer='uniform', activation=\"linear\"))\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KRmu1SO5u-n",
    "outputId": "4389fef5-472f-4da1-e674-601d7893285b",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run = 1\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 3.4814e-04 - mse: 3.4814e-04 - val_loss: 3.0982e-04 - val_mse: 3.0982e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.3160e-04 - mse: 2.3160e-04 - val_loss: 3.1378e-04 - val_mse: 3.1378e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2952e-04 - mse: 2.2952e-04 - val_loss: 3.1303e-04 - val_mse: 3.1303e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9172e-04 - mse: 1.9172e-04 - val_loss: 2.8150e-04 - val_mse: 2.8150e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.8375e-04 - mse: 1.8375e-04 - val_loss: 2.5666e-04 - val_mse: 2.5666e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.8211e-04 - mse: 1.8211e-04 - val_loss: 7.6707e-04 - val_mse: 7.6707e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.8692e-04 - mse: 1.8692e-04 - val_loss: 3.1508e-04 - val_mse: 3.1508e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.4777e-04 - mse: 2.4777e-04 - val_loss: 4.0306e-04 - val_mse: 4.0306e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.3106e-04 - mse: 2.3106e-04 - val_loss: 2.2896e-04 - val_mse: 2.2896e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9759e-04 - mse: 1.9759e-04 - val_loss: 2.7105e-04 - val_mse: 2.7105e-04\n",
      "\n",
      "Run = 2\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.3967e-04 - mse: 2.3967e-04 - val_loss: 2.6151e-04 - val_mse: 2.6151e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1392e-04 - mse: 2.1392e-04 - val_loss: 2.6948e-04 - val_mse: 2.6948e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.0803e-04 - mse: 2.0803e-04 - val_loss: 3.1260e-04 - val_mse: 3.1260e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.1585e-04 - mse: 2.1585e-04 - val_loss: 2.6552e-04 - val_mse: 2.6552e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.6246e-04 - mse: 2.6246e-04 - val_loss: 2.5070e-04 - val_mse: 2.5070e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0784e-04 - mse: 2.0784e-04 - val_loss: 2.3393e-04 - val_mse: 2.3393e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.8977e-04 - mse: 1.8977e-04 - val_loss: 2.2893e-04 - val_mse: 2.2893e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.8422e-04 - mse: 1.8422e-04 - val_loss: 3.8695e-04 - val_mse: 3.8695e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.7896e-04 - mse: 2.7896e-04 - val_loss: 2.4714e-04 - val_mse: 2.4714e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9203e-04 - mse: 1.9203e-04 - val_loss: 2.8783e-04 - val_mse: 2.8783e-04\n",
      "\n",
      "Run = 3\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.3141e-04 - mse: 2.3141e-04 - val_loss: 2.4783e-04 - val_mse: 2.4783e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0458e-04 - mse: 2.0458e-04 - val_loss: 2.9561e-04 - val_mse: 2.9561e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.3310e-04 - mse: 2.3310e-04 - val_loss: 3.4842e-04 - val_mse: 3.4842e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2833e-04 - mse: 2.2833e-04 - val_loss: 2.8385e-04 - val_mse: 2.8385e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9125e-04 - mse: 1.9125e-04 - val_loss: 2.5566e-04 - val_mse: 2.5566e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0751e-04 - mse: 2.0751e-04 - val_loss: 2.6390e-04 - val_mse: 2.6390e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0633e-04 - mse: 2.0633e-04 - val_loss: 2.2684e-04 - val_mse: 2.2684e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9558e-04 - mse: 1.9558e-04 - val_loss: 3.2127e-04 - val_mse: 3.2127e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.1231e-04 - mse: 2.1231e-04 - val_loss: 2.4807e-04 - val_mse: 2.4807e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9105e-04 - mse: 1.9105e-04 - val_loss: 3.0434e-04 - val_mse: 3.0434e-04\n",
      "\n",
      "Run = 4\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.5461e-04 - mse: 2.5461e-04 - val_loss: 3.1532e-04 - val_mse: 3.1532e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2797e-04 - mse: 2.2797e-04 - val_loss: 2.7119e-04 - val_mse: 2.7119e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0124e-04 - mse: 2.0124e-04 - val_loss: 3.2245e-04 - val_mse: 3.2245e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0510e-04 - mse: 2.0510e-04 - val_loss: 2.7963e-04 - val_mse: 2.7963e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1531e-04 - mse: 2.1531e-04 - val_loss: 2.5686e-04 - val_mse: 2.5686e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2288e-04 - mse: 2.2288e-04 - val_loss: 2.2247e-04 - val_mse: 2.2247e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.7909e-04 - mse: 1.7909e-04 - val_loss: 2.6556e-04 - val_mse: 2.6556e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.7744e-04 - mse: 1.7744e-04 - val_loss: 2.7440e-04 - val_mse: 2.7440e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 2.6349e-04 - mse: 2.6349e-04 - val_loss: 2.3449e-04 - val_mse: 2.3449e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.6944e-04 - mse: 1.6944e-04 - val_loss: 2.4177e-04 - val_mse: 2.4177e-04\n",
      "\n",
      "Run = 5\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.2892e-04 - mse: 2.2892e-04 - val_loss: 2.8038e-04 - val_mse: 2.8038e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.1932e-04 - mse: 2.1932e-04 - val_loss: 2.6922e-04 - val_mse: 2.6922e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2889e-04 - mse: 2.2889e-04 - val_loss: 2.8476e-04 - val_mse: 2.8476e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.3553e-04 - mse: 2.3553e-04 - val_loss: 2.8683e-04 - val_mse: 2.8683e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 2.0050e-04 - mse: 2.0050e-04 - val_loss: 2.4091e-04 - val_mse: 2.4091e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 2.1517e-04 - mse: 2.1517e-04 - val_loss: 2.4296e-04 - val_mse: 2.4296e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.1250e-04 - mse: 2.1250e-04 - val_loss: 2.4611e-04 - val_mse: 2.4611e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.8323e-04 - mse: 1.8323e-04 - val_loss: 3.4817e-04 - val_mse: 3.4817e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.6909e-04 - mse: 1.6909e-04 - val_loss: 4.6137e-04 - val_mse: 4.6137e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0181e-04 - mse: 2.0181e-04 - val_loss: 2.5345e-04 - val_mse: 2.5345e-04\n",
      "\n",
      "Run = 6\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 3.0228e-04 - mse: 3.0228e-04 - val_loss: 2.3555e-04 - val_mse: 2.3555e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1721e-04 - mse: 2.1721e-04 - val_loss: 2.6031e-04 - val_mse: 2.6031e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.3306e-04 - mse: 2.3306e-04 - val_loss: 2.8316e-04 - val_mse: 2.8316e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.8965e-04 - mse: 1.8965e-04 - val_loss: 2.5658e-04 - val_mse: 2.5658e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.1702e-04 - mse: 2.1702e-04 - val_loss: 2.3754e-04 - val_mse: 2.3754e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.3475e-04 - mse: 2.3475e-04 - val_loss: 2.6302e-04 - val_mse: 2.6302e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.4688e-04 - mse: 2.4688e-04 - val_loss: 4.0888e-04 - val_mse: 4.0888e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2940e-04 - mse: 2.2940e-04 - val_loss: 3.5592e-04 - val_mse: 3.5592e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9553e-04 - mse: 1.9553e-04 - val_loss: 2.2923e-04 - val_mse: 2.2923e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.8479e-04 - mse: 1.8479e-04 - val_loss: 2.4082e-04 - val_mse: 2.4082e-04\n",
      "\n",
      "Run = 7\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.3277e-04 - mse: 2.3277e-04 - val_loss: 2.2806e-04 - val_mse: 2.2806e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1008e-04 - mse: 2.1008e-04 - val_loss: 3.0580e-04 - val_mse: 3.0580e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.2731e-04 - mse: 2.2731e-04 - val_loss: 2.7008e-04 - val_mse: 2.7008e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2709e-04 - mse: 2.2709e-04 - val_loss: 3.4244e-04 - val_mse: 3.4244e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.9754e-04 - mse: 1.9754e-04 - val_loss: 2.9589e-04 - val_mse: 2.9589e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 2.3694e-04 - mse: 2.3694e-04 - val_loss: 2.4437e-04 - val_mse: 2.4437e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.0194e-04 - mse: 2.0194e-04 - val_loss: 2.8626e-04 - val_mse: 2.8626e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.8679e-04 - mse: 1.8679e-04 - val_loss: 2.9843e-04 - val_mse: 2.9843e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 1.9877e-04 - mse: 1.9877e-04 - val_loss: 2.2378e-04 - val_mse: 2.2378e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.8491e-04 - mse: 1.8491e-04 - val_loss: 2.4441e-04 - val_mse: 2.4441e-04\n",
      "\n",
      "Run = 8\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 2.7948e-04 - mse: 2.7948e-04 - val_loss: 2.9955e-04 - val_mse: 2.9955e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 2.1638e-04 - mse: 2.1638e-04 - val_loss: 3.0123e-04 - val_mse: 3.0123e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 2.2819e-04 - mse: 2.2819e-04 - val_loss: 3.0813e-04 - val_mse: 3.0813e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.2222e-04 - mse: 2.2222e-04 - val_loss: 2.5935e-04 - val_mse: 2.5935e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.9894e-04 - mse: 2.9894e-04 - val_loss: 2.6499e-04 - val_mse: 2.6499e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.9830e-04 - mse: 1.9830e-04 - val_loss: 2.3815e-04 - val_mse: 2.3815e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.5972e-04 - mse: 1.5972e-04 - val_loss: 2.6074e-04 - val_mse: 2.6074e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 1.9390e-04 - mse: 1.9390e-04 - val_loss: 3.0737e-04 - val_mse: 3.0737e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 3.0013e-04 - mse: 3.0013e-04 - val_loss: 2.6578e-04 - val_mse: 2.6578e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.9750e-04 - mse: 1.9750e-04 - val_loss: 2.8030e-04 - val_mse: 2.8030e-04\n",
      "\n",
      "Run = 9\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 2.8220e-04 - mse: 2.8220e-04 - val_loss: 3.5214e-04 - val_mse: 3.5214e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 2.2572e-04 - mse: 2.2572e-04 - val_loss: 2.8242e-04 - val_mse: 2.8242e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.1161e-04 - mse: 2.1161e-04 - val_loss: 2.7997e-04 - val_mse: 2.7997e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.9348e-04 - mse: 1.9348e-04 - val_loss: 2.8967e-04 - val_mse: 2.8967e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.2816e-04 - mse: 2.2816e-04 - val_loss: 2.3641e-04 - val_mse: 2.3641e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1061e-04 - mse: 2.1061e-04 - val_loss: 2.2645e-04 - val_mse: 2.2645e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9649e-04 - mse: 1.9649e-04 - val_loss: 2.8520e-04 - val_mse: 2.8520e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1191e-04 - mse: 2.1191e-04 - val_loss: 3.0252e-04 - val_mse: 3.0252e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.7559e-04 - mse: 1.7559e-04 - val_loss: 3.4289e-04 - val_mse: 3.4289e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.9449e-04 - mse: 1.9449e-04 - val_loss: 2.6891e-04 - val_mse: 2.6891e-04\n",
      "\n",
      "Run = 10\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.3176e-04 - mse: 2.3176e-04 - val_loss: 2.5507e-04 - val_mse: 2.5507e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.8600e-04 - mse: 1.8600e-04 - val_loss: 3.3669e-04 - val_mse: 3.3669e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.6690e-04 - mse: 2.6690e-04 - val_loss: 2.7304e-04 - val_mse: 2.7304e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.1643e-04 - mse: 2.1643e-04 - val_loss: 2.6635e-04 - val_mse: 2.6635e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.7964e-04 - mse: 1.7964e-04 - val_loss: 6.0208e-04 - val_mse: 6.0208e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1719e-04 - mse: 2.1719e-04 - val_loss: 3.4742e-04 - val_mse: 3.4742e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.8812e-04 - mse: 2.8812e-04 - val_loss: 2.5393e-04 - val_mse: 2.5393e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9454e-04 - mse: 1.9454e-04 - val_loss: 3.5328e-04 - val_mse: 3.5328e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0418e-04 - mse: 2.0418e-04 - val_loss: 2.9522e-04 - val_mse: 2.9522e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.8549e-04 - mse: 1.8549e-04 - val_loss: 3.4209e-04 - val_mse: 3.4209e-04\n"
     ]
    }
   ],
   "source": [
    "run,r2scores,msescores,maescores,pearsoncorr = [],[],[],[],[]\n",
    "for i in range(10):\n",
    "    print('\\nRun = {}'.format(i+1))\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size = 0.2,shuffle=True,random_state=81)\n",
    "    model = MLP2(np.shape(X_train)[1],np.shape(y_train)[1],81)\n",
    "    model.fit(np.array(X_train), np.array(y_train), epochs=10, batch_size=16, validation_split=0.2, shuffle=True)\n",
    "    y_pred = model.predict(np.array(X_test))\n",
    "    \n",
    "    #results\n",
    "    run.append(i+1)\n",
    "    \n",
    "    actual_mean = pd.DataFrame(y_test.mean(axis=1))\n",
    "    pred_mean = pd.DataFrame(y_pred.mean(axis=1))\n",
    "    r2scores.append(r2_score(actual_mean, pred_mean))\n",
    "    msescores.append(mean_squared_error(np.array(y_test), y_pred))\n",
    "    maescores.append(mean_absolute_error(np.array(y_test), y_pred))\n",
    "    \n",
    "    dist_orig = np.square(euclidean_distances(y_test, y_test)).flatten()\n",
    "    dist_pred = np.square(euclidean_distances(y_pred, y_pred)).flatten()\n",
    "    corr, _ = pearsonr(dist_orig, dist_pred)\n",
    "    pearsoncorr.append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "EdEHeH8_5u-o",
    "outputId": "8ee48991-8733-4e3f-d90f-b7837f4b630c",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Run</th>\n",
       "      <th>R2Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Correlation Coeff.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.886429</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.990071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.689397</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.004840</td>\n",
       "      <td>0.971116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.576506</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.005149</td>\n",
       "      <td>0.971069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.923627</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.986389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.774507</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>0.994018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.883063</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.004211</td>\n",
       "      <td>0.977817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.894151</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>0.988243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.866124</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.004300</td>\n",
       "      <td>0.989060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.912650</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.004026</td>\n",
       "      <td>0.990986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.764937</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.004468</td>\n",
       "      <td>0.975452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.817139</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.004381</td>\n",
       "      <td>0.983422</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     #Run   R2Score       MSE       MAE  Correlation Coeff.\n",
       "0     1.0  0.886429  0.000181  0.004198            0.990071\n",
       "1     2.0  0.689397  0.000230  0.004840            0.971116\n",
       "2     3.0  0.576506  0.000248  0.005149            0.971069\n",
       "3     4.0  0.923627  0.000182  0.004131            0.986389\n",
       "4     5.0  0.774507  0.000231  0.004423            0.994018\n",
       "5     6.0  0.883063  0.000196  0.004211            0.977817\n",
       "6     7.0  0.894151  0.000180  0.004066            0.988243\n",
       "7     8.0  0.866124  0.000185  0.004300            0.989060\n",
       "8     9.0  0.912650  0.000173  0.004026            0.990986\n",
       "9    10.0  0.764937  0.000240  0.004468            0.975452\n",
       "avg   5.5  0.817139  0.000205  0.004381            0.983422"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(zip(run,r2scores,msescores,maescores,pearsoncorr))\n",
    "result.columns = ['#Run','R2Score','MSE','MAE', 'Correlation Coeff.']\n",
    "result.loc[len(run)] = result.mean(numeric_only=True, axis=0)\n",
    "result.rename(index={len(run):'avg'},inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "id": "xU2mV9qO5u-o"
   },
   "outputs": [],
   "source": [
    "result.to_csv(dir+'Results/EGEOD75140/DNN_10PercentDropout_10runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "WKol0yMz-TzN",
    "outputId": "f05e78b8-7289-4265-c605-4666c860d1c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_59\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_87 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            multiple                  178150    \n",
      "_________________________________________________________________\n",
      "dropout_88 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            multiple                  96525     \n",
      "_________________________________________________________________\n",
      "dropout_89 (Dropout)         multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            multiple                  62376     \n",
      "=================================================================\n",
      "Total params: 337,051\n",
      "Trainable params: 337,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aYWTvMiy5u-s"
   },
   "source": [
    "**DNN with 10% dropout at input layer and 20% dropout at hidden layers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "VKYOUWYH5u-s"
   },
   "outputs": [],
   "source": [
    "def MLP3(x_shape,y_shape,rnd):\n",
    "    model = Sequential()\n",
    "    model.add(Dropout(0.1,seed=rnd))\n",
    "    model.add(Dense(350, input_dim=x_shape, kernel_initializer='uniform', activation=\"relu\"))\n",
    "    model.add(Dropout(0.2,seed=rnd))\n",
    "    model.add(Dense(275, kernel_initializer='uniform', activation=\"relu\"))\n",
    "    model.add(Dropout(0.2,seed=rnd))\n",
    "    model.add(Dense(y_shape, kernel_initializer='uniform', activation=\"linear\"))\n",
    "    model.compile(optimizer='adam',loss='mean_squared_error', metrics=['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TpbvG-Da5u-t",
    "outputId": "de9e333e-39d8-44a9-f780-4f61e5d4f39c",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run = 1\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.4277e-04 - mse: 2.4277e-04 - val_loss: 2.4907e-04 - val_mse: 2.4907e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0407e-04 - mse: 2.0407e-04 - val_loss: 2.8605e-04 - val_mse: 2.8605e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0681e-04 - mse: 2.0681e-04 - val_loss: 3.3235e-04 - val_mse: 3.3235e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0126e-04 - mse: 2.0126e-04 - val_loss: 3.1125e-04 - val_mse: 3.1125e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 9s 12ms/step - loss: 2.2467e-04 - mse: 2.2467e-04 - val_loss: 2.9239e-04 - val_mse: 2.9239e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9083e-04 - mse: 1.9083e-04 - val_loss: 2.4440e-04 - val_mse: 2.4440e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.4122e-04 - mse: 2.4122e-04 - val_loss: 2.5762e-04 - val_mse: 2.5762e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9694e-04 - mse: 1.9694e-04 - val_loss: 3.3299e-04 - val_mse: 3.3299e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.4700e-04 - mse: 2.4700e-04 - val_loss: 2.4919e-04 - val_mse: 2.4919e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2547e-04 - mse: 2.2547e-04 - val_loss: 3.2665e-04 - val_mse: 3.2665e-04\n",
      "\n",
      "Run = 2\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.2818e-04 - mse: 2.2818e-04 - val_loss: 2.6514e-04 - val_mse: 2.6514e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 1.9433e-04 - mse: 1.9433e-04 - val_loss: 3.2253e-04 - val_mse: 3.2253e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.3336e-04 - mse: 2.3336e-04 - val_loss: 3.0006e-04 - val_mse: 3.0006e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.5501e-04 - mse: 2.5501e-04 - val_loss: 3.3465e-04 - val_mse: 3.3465e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.4923e-04 - mse: 2.4923e-04 - val_loss: 2.5448e-04 - val_mse: 2.5448e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.1201e-04 - mse: 2.1201e-04 - val_loss: 2.4531e-04 - val_mse: 2.4531e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.8986e-04 - mse: 1.8986e-04 - val_loss: 4.3373e-04 - val_mse: 4.3373e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.8622e-04 - mse: 1.8622e-04 - val_loss: 4.0725e-04 - val_mse: 4.0725e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.0595e-04 - mse: 2.0595e-04 - val_loss: 2.6003e-04 - val_mse: 2.6003e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9703e-04 - mse: 1.9703e-04 - val_loss: 2.4636e-04 - val_mse: 2.4636e-04\n",
      "\n",
      "Run = 3\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2708e-04 - mse: 2.2708e-04 - val_loss: 2.4570e-04 - val_mse: 2.4570e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.1773e-04 - mse: 2.1773e-04 - val_loss: 2.8117e-04 - val_mse: 2.8117e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.4789e-04 - mse: 2.4789e-04 - val_loss: 2.4870e-04 - val_mse: 2.4870e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1559e-04 - mse: 2.1559e-04 - val_loss: 3.7546e-04 - val_mse: 3.7546e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0559e-04 - mse: 2.0559e-04 - val_loss: 2.8758e-04 - val_mse: 2.8758e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.7891e-04 - mse: 2.7891e-04 - val_loss: 2.4745e-04 - val_mse: 2.4745e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.3408e-04 - mse: 2.3408e-04 - val_loss: 2.8605e-04 - val_mse: 2.8605e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.4845e-04 - mse: 2.4845e-04 - val_loss: 4.4799e-04 - val_mse: 4.4799e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.3446e-04 - mse: 2.3446e-04 - val_loss: 2.6523e-04 - val_mse: 2.6523e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.2949e-04 - mse: 2.2949e-04 - val_loss: 2.8917e-04 - val_mse: 2.8917e-04\n",
      "\n",
      "Run = 4\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.6178e-04 - mse: 2.6178e-04 - val_loss: 2.5744e-04 - val_mse: 2.5744e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2515e-04 - mse: 2.2515e-04 - val_loss: 2.5902e-04 - val_mse: 2.5902e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0796e-04 - mse: 2.0796e-04 - val_loss: 3.4072e-04 - val_mse: 3.4072e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 11s 14ms/step - loss: 2.2897e-04 - mse: 2.2897e-04 - val_loss: 3.0020e-04 - val_mse: 3.0020e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.2512e-04 - mse: 2.2512e-04 - val_loss: 2.5369e-04 - val_mse: 2.5369e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.9551e-04 - mse: 1.9551e-04 - val_loss: 2.4964e-04 - val_mse: 2.4964e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1064e-04 - mse: 2.1064e-04 - val_loss: 3.2953e-04 - val_mse: 3.2953e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.4413e-04 - mse: 2.4413e-04 - val_loss: 2.9666e-04 - val_mse: 2.9666e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.9441e-04 - mse: 1.9441e-04 - val_loss: 3.0469e-04 - val_mse: 3.0469e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9626e-04 - mse: 1.9626e-04 - val_loss: 2.4805e-04 - val_mse: 2.4805e-04\n",
      "\n",
      "Run = 5\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.8304e-04 - mse: 2.8304e-04 - val_loss: 2.7883e-04 - val_mse: 2.7883e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1350e-04 - mse: 2.1350e-04 - val_loss: 3.2201e-04 - val_mse: 3.2201e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.3227e-04 - mse: 2.3227e-04 - val_loss: 2.4847e-04 - val_mse: 2.4847e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2007e-04 - mse: 2.2007e-04 - val_loss: 3.2144e-04 - val_mse: 3.2144e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.3337e-04 - mse: 2.3337e-04 - val_loss: 3.4725e-04 - val_mse: 3.4725e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0609e-04 - mse: 2.0609e-04 - val_loss: 2.4930e-04 - val_mse: 2.4930e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1992e-04 - mse: 2.1992e-04 - val_loss: 2.7539e-04 - val_mse: 2.7539e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.8640e-04 - mse: 1.8640e-04 - val_loss: 4.1465e-04 - val_mse: 4.1465e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0834e-04 - mse: 2.0834e-04 - val_loss: 2.7634e-04 - val_mse: 2.7634e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1815e-04 - mse: 2.1815e-04 - val_loss: 2.5042e-04 - val_mse: 2.5042e-04\n",
      "\n",
      "Run = 6\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.6958e-04 - mse: 2.6958e-04 - val_loss: 2.7578e-04 - val_mse: 2.7578e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.9419e-04 - mse: 1.9419e-04 - val_loss: 2.7769e-04 - val_mse: 2.7769e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.5053e-04 - mse: 2.5053e-04 - val_loss: 4.4342e-04 - val_mse: 4.4342e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2475e-04 - mse: 2.2475e-04 - val_loss: 2.5812e-04 - val_mse: 2.5812e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0614e-04 - mse: 2.0614e-04 - val_loss: 2.9335e-04 - val_mse: 2.9335e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2626e-04 - mse: 2.2626e-04 - val_loss: 2.7262e-04 - val_mse: 2.7262e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.4838e-04 - mse: 2.4838e-04 - val_loss: 4.4354e-04 - val_mse: 4.4354e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0208e-04 - mse: 2.0208e-04 - val_loss: 2.4451e-04 - val_mse: 2.4451e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.5051e-04 - mse: 2.5051e-04 - val_loss: 2.8297e-04 - val_mse: 2.8297e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0467e-04 - mse: 2.0467e-04 - val_loss: 2.6789e-04 - val_mse: 2.6789e-04\n",
      "\n",
      "Run = 7\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.3344e-04 - mse: 2.3344e-04 - val_loss: 2.4116e-04 - val_mse: 2.4116e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2983e-04 - mse: 2.2983e-04 - val_loss: 2.6501e-04 - val_mse: 2.6501e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0454e-04 - mse: 2.0454e-04 - val_loss: 2.7667e-04 - val_mse: 2.7667e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.9094e-04 - mse: 1.9094e-04 - val_loss: 2.6010e-04 - val_mse: 2.6010e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.0065e-04 - mse: 2.0065e-04 - val_loss: 2.5673e-04 - val_mse: 2.5673e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1583e-04 - mse: 2.1583e-04 - val_loss: 2.6719e-04 - val_mse: 2.6719e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.5647e-04 - mse: 2.5647e-04 - val_loss: 3.7486e-04 - val_mse: 3.7486e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1147e-04 - mse: 2.1147e-04 - val_loss: 3.4868e-04 - val_mse: 3.4868e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.7151e-04 - mse: 2.7151e-04 - val_loss: 2.6304e-04 - val_mse: 2.6304e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1567e-04 - mse: 2.1567e-04 - val_loss: 3.1562e-04 - val_mse: 3.1562e-04\n",
      "\n",
      "Run = 8\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 3.1075e-04 - mse: 3.1075e-04 - val_loss: 3.1365e-04 - val_mse: 3.1365e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1033e-04 - mse: 2.1033e-04 - val_loss: 2.5796e-04 - val_mse: 2.5796e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2505e-04 - mse: 2.2505e-04 - val_loss: 2.6617e-04 - val_mse: 2.6617e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.8525e-04 - mse: 1.8525e-04 - val_loss: 2.6561e-04 - val_mse: 2.6561e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0904e-04 - mse: 2.0904e-04 - val_loss: 2.9101e-04 - val_mse: 2.9101e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.3678e-04 - mse: 2.3678e-04 - val_loss: 2.6951e-04 - val_mse: 2.6951e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.4639e-04 - mse: 2.4639e-04 - val_loss: 2.7160e-04 - val_mse: 2.7160e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0250e-04 - mse: 2.0250e-04 - val_loss: 2.9131e-04 - val_mse: 2.9131e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1684e-04 - mse: 2.1684e-04 - val_loss: 3.4623e-04 - val_mse: 3.4623e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1519e-04 - mse: 2.1519e-04 - val_loss: 4.1855e-04 - val_mse: 4.1855e-04\n",
      "\n",
      "Run = 9\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2185e-04 - mse: 2.2185e-04 - val_loss: 3.2385e-04 - val_mse: 3.2385e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.9384e-04 - mse: 1.9384e-04 - val_loss: 3.6887e-04 - val_mse: 3.6887e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.4267e-04 - mse: 2.4267e-04 - val_loss: 3.1064e-04 - val_mse: 3.1064e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0795e-04 - mse: 2.0795e-04 - val_loss: 3.1510e-04 - val_mse: 3.1510e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 1.8756e-04 - mse: 1.8756e-04 - val_loss: 2.4346e-04 - val_mse: 2.4346e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.2279e-04 - mse: 2.2279e-04 - val_loss: 2.9396e-04 - val_mse: 2.9396e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1931e-04 - mse: 2.1931e-04 - val_loss: 3.0246e-04 - val_mse: 3.0246e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0552e-04 - mse: 2.0552e-04 - val_loss: 4.7621e-04 - val_mse: 4.7621e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.3736e-04 - mse: 2.3736e-04 - val_loss: 3.5511e-04 - val_mse: 3.5511e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.0832e-04 - mse: 2.0832e-04 - val_loss: 2.3033e-04 - val_mse: 2.3033e-04\n",
      "\n",
      "Run = 10\n",
      "Epoch 1/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 4.6384e-04 - mse: 4.6384e-04 - val_loss: 3.3732e-04 - val_mse: 3.3732e-04\n",
      "Epoch 2/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.1779e-04 - mse: 2.1779e-04 - val_loss: 3.3631e-04 - val_mse: 3.3631e-04\n",
      "Epoch 3/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.3724e-04 - mse: 2.3724e-04 - val_loss: 2.8070e-04 - val_mse: 2.8070e-04\n",
      "Epoch 4/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.4300e-04 - mse: 2.4300e-04 - val_loss: 3.8181e-04 - val_mse: 3.8181e-04\n",
      "Epoch 5/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.1188e-04 - mse: 2.1188e-04 - val_loss: 2.4265e-04 - val_mse: 2.4265e-04\n",
      "Epoch 6/10\n",
      "762/762 [==============================] - 10s 13ms/step - loss: 2.5770e-04 - mse: 2.5770e-04 - val_loss: 2.4559e-04 - val_mse: 2.4559e-04\n",
      "Epoch 7/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 2.4873e-04 - mse: 2.4873e-04 - val_loss: 2.4521e-04 - val_mse: 2.4521e-04\n",
      "Epoch 8/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.8797e-04 - mse: 1.8797e-04 - val_loss: 2.5799e-04 - val_mse: 2.5799e-04\n",
      "Epoch 9/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.9987e-04 - mse: 1.9987e-04 - val_loss: 2.6665e-04 - val_mse: 2.6665e-04\n",
      "Epoch 10/10\n",
      "762/762 [==============================] - 10s 14ms/step - loss: 1.8511e-04 - mse: 1.8511e-04 - val_loss: 3.3624e-04 - val_mse: 3.3624e-04\n"
     ]
    }
   ],
   "source": [
    "run,r2scores,msescores,maescores,pearsoncorr = [],[],[],[],[]\n",
    "for i in range(10):\n",
    "    print('\\nRun = {}'.format(i+1))\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size = 0.2,shuffle=True,random_state=81)\n",
    "    model = MLP3(np.shape(X_train)[1],np.shape(y_train)[1],81)\n",
    "    model.fit(np.array(X_train), np.array(y_train), epochs=10, batch_size=16, validation_split=0.2, shuffle=True)\n",
    "    y_pred = model.predict(np.array(X_test))\n",
    "    \n",
    "    #results\n",
    "    run.append(i+1)\n",
    "    \n",
    "    actual_mean = pd.DataFrame(y_test.mean(axis=1))\n",
    "    pred_mean = pd.DataFrame(y_pred.mean(axis=1))\n",
    "    r2scores.append(r2_score(actual_mean, pred_mean))\n",
    "    msescores.append(mean_squared_error(np.array(y_test), y_pred))\n",
    "    maescores.append(mean_absolute_error(np.array(y_test), y_pred))\n",
    "    \n",
    "    dist_orig = np.square(euclidean_distances(y_test, y_test)).flatten()\n",
    "    dist_pred = np.square(euclidean_distances(y_pred, y_pred)).flatten()\n",
    "    corr, _ = pearsonr(dist_orig, dist_pred)\n",
    "    pearsoncorr.append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "m1bE-rWl5u-t",
    "outputId": "f87ef53e-d7b3-4450-915f-43689692d5dd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Run</th>\n",
       "      <th>R2Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Correlation Coeff.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.711825</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.004638</td>\n",
       "      <td>0.993124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.828553</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>0.991449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.827131</td>\n",
       "      <td>0.000192</td>\n",
       "      <td>0.004181</td>\n",
       "      <td>0.992584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.797973</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.004048</td>\n",
       "      <td>0.988535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.911359</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.004654</td>\n",
       "      <td>0.992954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.819778</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.004406</td>\n",
       "      <td>0.975915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.196189</td>\n",
       "      <td>0.000343</td>\n",
       "      <td>0.004317</td>\n",
       "      <td>0.977341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.670804</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.004849</td>\n",
       "      <td>0.972601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.783868</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.003902</td>\n",
       "      <td>0.977184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.634685</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>0.004471</td>\n",
       "      <td>0.982888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.718217</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.984457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     #Run   R2Score       MSE       MAE  Correlation Coeff.\n",
       "0     1.0  0.711825  0.000218  0.004638            0.993124\n",
       "1     2.0  0.828553  0.000204  0.003868            0.991449\n",
       "2     3.0  0.827131  0.000192  0.004181            0.992584\n",
       "3     4.0  0.797973  0.000222  0.004048            0.988535\n",
       "4     5.0  0.911359  0.000188  0.004654            0.992954\n",
       "5     6.0  0.819778  0.000250  0.004406            0.975915\n",
       "6     7.0  0.196189  0.000343  0.004317            0.977341\n",
       "7     8.0  0.670804  0.000224  0.004849            0.972601\n",
       "8     9.0  0.783868  0.000216  0.003902            0.977184\n",
       "9    10.0  0.634685  0.000274  0.004471            0.982888\n",
       "avg   5.5  0.718217  0.000233  0.004333            0.984457"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(zip(run,r2scores,msescores,maescores,pearsoncorr))\n",
    "result.columns = ['#Run','R2Score','MSE','MAE','Correlation Coeff.']\n",
    "result.loc[len(run)] = result.mean(numeric_only=True, axis=0)\n",
    "result.rename(index={len(run):'avg'},inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "id": "-IQdeDBN5u-u"
   },
   "outputs": [],
   "source": [
    "result.to_csv(dir+'Results/EGEOD75140/DNN_10Percent20PercentDropout_10runs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "DrbZwUP3-Vpc",
    "outputId": "649bf100-1b69-453f-c4db-afd750da27e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_69\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout_117 (Dropout)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            multiple                  178150    \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            multiple                  96525     \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        multiple                  0         \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            multiple                  62376     \n",
      "=================================================================\n",
      "Total params: 337,051\n",
      "Trainable params: 337,051\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QyxLod3yDJF3"
   },
   "source": [
    "# Benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "5VBcRZR1B0Wg"
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RXMuqJrEDWWG"
   },
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TOSzLIKjDSYu",
    "outputId": "50a10bc5-0e3f-450f-c848-e0492bb25725"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Run = 1\n",
      "\n",
      "Run = 2\n",
      "\n",
      "Run = 3\n",
      "\n",
      "Run = 4\n",
      "\n",
      "Run = 5\n",
      "\n",
      "Run = 6\n",
      "\n",
      "Run = 7\n",
      "\n",
      "Run = 8\n",
      "\n",
      "Run = 9\n",
      "\n",
      "Run = 10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "rnd_state_lr,r2scores_lr,msescores_lr,maescores_lr,pearsoncorr = [],[],[],[],[]\n",
    "\n",
    "for i in range(10):\n",
    "    print('\\nRun = {}'.format(i+1))\n",
    "    X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size = 0.2,shuffle=True,random_state=81)\n",
    "    linear_Regr = LinearRegression(normalize=True)\n",
    "    linear_Regr.fit(X_train, y_train)\n",
    "    y_pred = linear_Regr.predict(X_test)\n",
    "\n",
    "    run.append(i+1)\n",
    "\n",
    "    actual_mean = pd.DataFrame(y_test.mean(axis=1))\n",
    "    pred_mean = pd.DataFrame(y_pred.mean(axis=1))\n",
    "    r2scores_lr.append(r2_score(actual_mean, pred_mean))\n",
    "    msescores_lr.append(mean_squared_error(y_test, y_pred))\n",
    "    maescores_lr.append(mean_absolute_error(y_test, y_pred))\n",
    "    \n",
    "    dist_orig = np.square(euclidean_distances(y_test, y_test)).flatten()\n",
    "    dist_pred = np.square(euclidean_distances(y_pred, y_pred)).flatten()\n",
    "    corr, _ = pearsonr(dist_orig, dist_pred)\n",
    "    pearsoncorr.append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "VHMVPkgd5u-y",
    "outputId": "76e959ee-ce9a-4875-addb-6973461283de"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#Run</th>\n",
       "      <th>R2Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Correlation Coeff.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.693563</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.984159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.693563</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.984159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.693563</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.984159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.693563</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.984159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.693563</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.984159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.693563</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.984159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.693563</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.984159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.693563</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.984159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.693563</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.984159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.693563</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.984159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.693563</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.984159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     #Run   R2Score       MSE       MAE  Correlation Coeff.\n",
       "0     1.0  0.693563  0.000225  0.004599            0.984159\n",
       "1     2.0  0.693563  0.000225  0.004599            0.984159\n",
       "2     3.0  0.693563  0.000225  0.004599            0.984159\n",
       "3     4.0  0.693563  0.000225  0.004599            0.984159\n",
       "4     5.0  0.693563  0.000225  0.004599            0.984159\n",
       "5     6.0  0.693563  0.000225  0.004599            0.984159\n",
       "6     7.0  0.693563  0.000225  0.004599            0.984159\n",
       "7     8.0  0.693563  0.000225  0.004599            0.984159\n",
       "8     9.0  0.693563  0.000225  0.004599            0.984159\n",
       "9    10.0  0.693563  0.000225  0.004599            0.984159\n",
       "avg   5.5  0.693563  0.000225  0.004599            0.984159"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(zip(run,r2scores_lr,msescores_lr,maescores_lr,pearsoncorr))\n",
    "result.columns = ['#Run','R2Score','MSE','MAE','Correlation Coeff.']\n",
    "result.loc[len(run)] = result.mean(numeric_only=True, axis=0)\n",
    "result.rename(index={len(run):'avg'},inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "XDmh9maH5u-z"
   },
   "outputs": [],
   "source": [
    "result.to_csv(dir+'Results/EGEOD75140/LinearRegression_10runs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9d3EKNHF4Ap"
   },
   "source": [
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9jzWOKAZFwqi",
    "outputId": "8eae06ad-cb56-4c02-f599-a4c3c883a8d6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with alpha = 1e-05\n",
      "Working with alpha = 5e-05\n",
      "Working with alpha = 0.0001\n",
      "Working with alpha = 0.0005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with alpha = 0.001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with alpha = 0.005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with alpha = 0.01\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with alpha = 0.05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with alpha = 0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with alpha = 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/scipy/stats/stats.py:3508: PearsonRConstantInputWarning: An input array is constant; the correlation coefficent is not defined.\n",
      "  warnings.warn(PearsonRConstantInputWarning())\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "alpha,ls_r2,ls_mse,ls_mae,pearsoncorr = [],[],[],[],[]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size = 0.2,shuffle=True,random_state=81)\n",
    "actual_mean = pd.DataFrame(y_test.mean(axis=1))\n",
    "\n",
    "#for alp in [0.01,0.05,0.1,0.2,0.5,1,2,2.5,5,10]:\n",
    "for alp in [0.00001,0.00005,0.0001,0.0005,0.001,0.005,0.01,0.05,0.1,0.5]:\n",
    "    print('Working with alpha =',alp)\n",
    "    Lasso_Regr = Lasso(alpha=alp, normalize=True)\n",
    "    Lasso_Regr.fit(X_train,y_train)\n",
    "    y_pred = Lasso_Regr.predict(X_test)\n",
    "    \n",
    "    alpha.append(alp)\n",
    "    \n",
    "    pred_mean = pd.DataFrame(y_pred.mean(axis=1))\n",
    "    ls_r2.append(r2_score(actual_mean, pred_mean))\n",
    "    ls_mse.append(mean_squared_error(y_test, y_pred))\n",
    "    ls_mae.append(mean_absolute_error(y_test, y_pred))\n",
    "    \n",
    "    dist_orig = np.square(euclidean_distances(y_test, y_test)).flatten()\n",
    "    dist_pred = np.square(euclidean_distances(y_pred, y_pred)).flatten()\n",
    "    corr, _ = pearsonr(dist_orig, dist_pred)\n",
    "    pearsoncorr.append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "QbLFjfai5u-2",
    "outputId": "e0f2f8fc-9c5b-4242-bd64-24bba68d0065"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>R2Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Correlation Coeff.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.801662</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.981755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.872085</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>0.980781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.260974</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>0.004976</td>\n",
       "      <td>0.984559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000500</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001000</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.005000</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.010000</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.050000</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.100000</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.000248</td>\n",
       "      <td>0.000366</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>0.066666</td>\n",
       "      <td>0.193298</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>0.004948</td>\n",
       "      <td>0.982365</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Alpha   R2Score       MSE       MAE  Correlation Coeff.\n",
       "0    0.000010  0.801662  0.000187  0.003609            0.981755\n",
       "1    0.000050  0.872085  0.000176  0.004086            0.980781\n",
       "2    0.000100  0.260974  0.000305  0.004976            0.984559\n",
       "3    0.000500 -0.000248  0.000366  0.005258                 NaN\n",
       "4    0.001000 -0.000248  0.000366  0.005258                 NaN\n",
       "5    0.005000 -0.000248  0.000366  0.005258                 NaN\n",
       "6    0.010000 -0.000248  0.000366  0.005258                 NaN\n",
       "7    0.050000 -0.000248  0.000366  0.005258                 NaN\n",
       "8    0.100000 -0.000248  0.000366  0.005258                 NaN\n",
       "9    0.500000 -0.000248  0.000366  0.005258                 NaN\n",
       "avg  0.066666  0.193298  0.000323  0.004948            0.982365"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(zip(alpha,ls_r2,ls_mse,ls_mae,pearsoncorr))\n",
    "result.columns = ['Alpha','R2Score','MSE','MAE','Correlation Coeff.']\n",
    "result.loc[len(alpha)] = result.mean(numeric_only=True, axis=0)\n",
    "result.rename(index={len(alpha):'avg'},inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "id": "UEhTIj2a5u-2"
   },
   "outputs": [],
   "source": [
    "result.to_csv(dir+'Results/EGEOD75140/LassoRegression_10runs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gDukM2LWjsGO"
   },
   "source": [
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NXBT6ZilHWZL",
    "outputId": "20d84968-cef3-42f1-ae3f-d11225aee29b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working with alpha =  0.01\n",
      "Working with alpha =  0.05\n",
      "Working with alpha =  0.1\n",
      "Working with alpha =  0.5\n",
      "Working with alpha =  1\n",
      "Working with alpha =  2\n",
      "Working with alpha =  3\n",
      "Working with alpha =  4\n",
      "Working with alpha =  5\n",
      "Working with alpha =  10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "alpha,rg_r2,rg_mse,rg_mae,pearsoncorr = [],[],[],[],[]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size = 0.2,shuffle=True,random_state=81)\n",
    "actual_mean = pd.DataFrame(y_test.mean(axis=1))\n",
    "\n",
    "for alp in [0.01,0.05,0.1,0.5,1,2,3,4,5,10]:\n",
    "    print('Working with alpha = ',alp)\n",
    "    Ridge_Regr = Ridge(alpha=alp, normalize=True)\n",
    "    Ridge_Regr.fit(X_train, y_train)\n",
    "    y_pred = Ridge_Regr.predict(X_test)\n",
    "    \n",
    "    alpha.append(alp)\n",
    "    \n",
    "    pred_mean = pd.DataFrame(y_pred.mean(axis=1))\n",
    "    rg_r2.append(r2_score(actual_mean, pred_mean))\n",
    "    rg_mse.append(mean_squared_error(y_test, y_pred))\n",
    "    rg_mae.append(mean_absolute_error(y_test, y_pred))\n",
    "    \n",
    "    dist_orig = np.square(euclidean_distances(y_test, y_test)).flatten()\n",
    "    dist_pred = np.square(euclidean_distances(y_pred, y_pred)).flatten()\n",
    "    corr, _ = pearsonr(dist_orig, dist_pred)\n",
    "    pearsoncorr.append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "1XFxEgCr5u-7",
    "outputId": "a4a5e9da-83e9-4364-bdf3-d5f14e7356ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alpha</th>\n",
       "      <th>R2Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Correlation Coeff.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.695894</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.004499</td>\n",
       "      <td>0.984003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.050</td>\n",
       "      <td>0.700956</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.004264</td>\n",
       "      <td>0.983571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.100</td>\n",
       "      <td>0.702576</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.983194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.500</td>\n",
       "      <td>0.700679</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.003774</td>\n",
       "      <td>0.981892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.000</td>\n",
       "      <td>0.711219</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.003672</td>\n",
       "      <td>0.981539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.000</td>\n",
       "      <td>0.743596</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.003609</td>\n",
       "      <td>0.981720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.000</td>\n",
       "      <td>0.774240</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.003591</td>\n",
       "      <td>0.982173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.000</td>\n",
       "      <td>0.800362</td>\n",
       "      <td>0.000180</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.982676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5.000</td>\n",
       "      <td>0.822356</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.003584</td>\n",
       "      <td>0.983175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.000</td>\n",
       "      <td>0.891984</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.003599</td>\n",
       "      <td>0.985333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>2.566</td>\n",
       "      <td>0.754386</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.003829</td>\n",
       "      <td>0.982928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Alpha   R2Score       MSE       MAE  Correlation Coeff.\n",
       "0     0.010  0.695894  0.000221  0.004499            0.984003\n",
       "1     0.050  0.700956  0.000213  0.004264            0.983571\n",
       "2     0.100  0.702576  0.000209  0.004113            0.983194\n",
       "3     0.500  0.700679  0.000201  0.003774            0.981892\n",
       "4     1.000  0.711219  0.000198  0.003672            0.981539\n",
       "5     2.000  0.743596  0.000191  0.003609            0.981720\n",
       "6     3.000  0.774240  0.000185  0.003591            0.982173\n",
       "7     4.000  0.800362  0.000180  0.003585            0.982676\n",
       "8     5.000  0.822356  0.000176  0.003584            0.983175\n",
       "9    10.000  0.891984  0.000162  0.003599            0.985333\n",
       "avg   2.566  0.754386  0.000194  0.003829            0.982928"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(zip(alpha,rg_r2,rg_mse,rg_mae,pearsoncorr))\n",
    "result.columns = ['Alpha','R2Score','MSE','MAE','Correlation Coeff.']\n",
    "result.loc[len(alpha)] = result.mean(numeric_only=True, axis=0)\n",
    "result.rename(index={len(alpha):'avg'},inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "id": "EDNEjlWt5u-7"
   },
   "outputs": [],
   "source": [
    "result.to_csv(dir+'Results/EGEOD75140/RidgeRegression_10runs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kav5r__yqC1V"
   },
   "source": [
    "# k-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8GxLmGfkpy3w",
    "outputId": "b72d5494-a378-46d8-95b2-cdc479f0fb2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k= 1\n",
      "k= 5\n",
      "k= 9\n",
      "k= 11\n",
      "k= 15\n",
      "k= 19\n",
      "k= 21\n",
      "k= 25\n",
      "k= 29\n",
      "k= 31\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "knn,knn_r2,knn_mse,knn_mae=[],[],[],[]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size = 0.2,shuffle=True,random_state=81)\n",
    "actual_mean = pd.DataFrame(y_test.mean(axis=1))\n",
    "\n",
    "for k in [1,5,9,11,15,19,21,25,29,31]:\n",
    "    print('k=',k)\n",
    "    knn_Regr = KNeighborsRegressor(n_neighbors=k, n_jobs=-1)\n",
    "    knn_Regr.fit(X_train, y_train)\n",
    "    y_pred = knn_Regr.predict(X_test)\n",
    "    pred_mean = pd.DataFrame(y_pred.mean(axis=1))\n",
    "    knn.append(k)\n",
    "    knn_r2.append(r2_score(actual_mean, pred_mean))\n",
    "    knn_mse.append(mean_squared_error(y_test, y_pred))\n",
    "    knn_mae.append(mean_absolute_error(y_test, y_pred))\n",
    "\n",
    "    dist_orig = np.square(euclidean_distances(y_test, y_test)).flatten()\n",
    "    dist_pred = np.square(euclidean_distances(y_pred, y_pred)).flatten()\n",
    "    corr, _ = pearsonr(dist_orig, dist_pred)\n",
    "    pearsoncorr.append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "EX60668T5u_D",
    "outputId": "a91d97a6-c091-49cb-c190-eb3f58f0470a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>k</th>\n",
       "      <th>R2Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Correlation Coeff.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.897643</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.003401</td>\n",
       "      <td>0.984003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.773567</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.983571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.790005</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.983194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.0</td>\n",
       "      <td>0.773474</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.003131</td>\n",
       "      <td>0.981892</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15.0</td>\n",
       "      <td>0.727794</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.003135</td>\n",
       "      <td>0.981539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>19.0</td>\n",
       "      <td>0.679658</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.981720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21.0</td>\n",
       "      <td>0.664758</td>\n",
       "      <td>0.000213</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.982173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>25.0</td>\n",
       "      <td>0.628540</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.003141</td>\n",
       "      <td>0.982676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>29.0</td>\n",
       "      <td>0.611928</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.983175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>31.0</td>\n",
       "      <td>0.600038</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.003144</td>\n",
       "      <td>0.985333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>16.6</td>\n",
       "      <td>0.714740</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>0.982928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        k   R2Score       MSE       MAE  Correlation Coeff.\n",
       "0     1.0  0.897643  0.000204  0.003401            0.984003\n",
       "1     5.0  0.773567  0.000189  0.003159            0.983571\n",
       "2     9.0  0.790005  0.000188  0.003141            0.983194\n",
       "3    11.0  0.773474  0.000190  0.003131            0.981892\n",
       "4    15.0  0.727794  0.000200  0.003135            0.981539\n",
       "5    19.0  0.679658  0.000210  0.003141            0.981720\n",
       "6    21.0  0.664758  0.000213  0.003139            0.982173\n",
       "7    25.0  0.628540  0.000221  0.003141            0.982676\n",
       "8    29.0  0.611928  0.000225  0.003143            0.983175\n",
       "9    31.0  0.600038  0.000227  0.003144            0.985333\n",
       "avg  16.6  0.714740  0.000207  0.003167            0.982928"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(zip(knn,knn_r2,knn_mse,knn_mae,pearsoncorr))\n",
    "result.columns = ['k','R2Score','MSE','MAE','Correlation Coeff.']\n",
    "result.loc[len(knn)] = result.mean(numeric_only=True, axis=0)\n",
    "result.rename(index={len(knn):'avg'},inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "id": "rK64h62V5u_E"
   },
   "outputs": [],
   "source": [
    "result.to_csv(dir+'Results/EGEOD75140/kNNRegression_10runs.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CALVTtl3m1Bh"
   },
   "source": [
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lM5zTktSmfz4",
    "outputId": "fbc37b3a-c470-42e8-e0cd-5e60d1712211"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "estimators =  1\n",
      "estimators =  2\n",
      "estimators =  3\n",
      "estimators =  4\n",
      "estimators =  5\n",
      "estimators =  6\n",
      "estimators =  7\n",
      "estimators =  8\n",
      "estimators =  9\n",
      "estimators =  10\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "estimators,rf_r2,rf_mse,rf_mae,pearsoncorr = [],[],[],[],[]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_data,y_data,test_size = 0.2,shuffle=True,random_state=81)\n",
    "actual_mean = pd.DataFrame(y_test.mean(axis=1))\n",
    "\n",
    "for est in [1,2,3,4,5,6,7,8,9,10]:\n",
    "    print('estimators = ',est)\n",
    "    rf_Regr = RandomForestRegressor(n_estimators=est, n_jobs=-1)\n",
    "    rf_Regr.fit(X_train, y_train)\n",
    "    y_pred = rf_Regr.predict(X_test)\n",
    "    \n",
    "    estimators.append(est)\n",
    "    \n",
    "    pred_mean = pd.DataFrame(y_pred.mean(axis=1))\n",
    "    rf_r2.append(r2_score(actual_mean, pred_mean))\n",
    "    rf_mse.append(mean_squared_error(y_test, y_pred))\n",
    "    rf_mae.append(mean_absolute_error(y_test, y_pred))\n",
    "    \n",
    "    dist_orig = np.square(euclidean_distances(y_test, y_test)).flatten()\n",
    "    dist_pred = np.square(euclidean_distances(y_pred, y_pred)).flatten()\n",
    "    corr, _ = pearsonr(dist_orig, dist_pred)\n",
    "    pearsoncorr.append(corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 394
    },
    "id": "_i6My7wY5u-_",
    "outputId": "65d0bcf1-1a81-42e4-f9a1-c5614255f6e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Estimators</th>\n",
       "      <th>R2Score</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>Correlation Coeff.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.713648</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.004603</td>\n",
       "      <td>0.895836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.869965</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.004131</td>\n",
       "      <td>0.968224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.765845</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.004057</td>\n",
       "      <td>0.921915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.877948</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.003985</td>\n",
       "      <td>0.982253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.872770</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.003880</td>\n",
       "      <td>0.978603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.906205</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.003874</td>\n",
       "      <td>0.991350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.920334</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.003819</td>\n",
       "      <td>0.986838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.0</td>\n",
       "      <td>0.890108</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.984276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.0</td>\n",
       "      <td>0.910532</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.988963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.0</td>\n",
       "      <td>0.869386</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.989246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.859674</td>\n",
       "      <td>0.000215</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.968751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Estimators   R2Score       MSE       MAE  Correlation Coeff.\n",
       "0           1.0  0.713648  0.000362  0.004603            0.895836\n",
       "1           2.0  0.869965  0.000241  0.004131            0.968224\n",
       "2           3.0  0.765845  0.000234  0.004057            0.921915\n",
       "3           4.0  0.877948  0.000205  0.003985            0.982253\n",
       "4           5.0  0.872770  0.000195  0.003880            0.978603\n",
       "5           6.0  0.906205  0.000188  0.003874            0.991350\n",
       "6           7.0  0.920334  0.000183  0.003819            0.986838\n",
       "7           8.0  0.890108  0.000183  0.003808            0.984276\n",
       "8           9.0  0.910532  0.000177  0.003779            0.988963\n",
       "9          10.0  0.869386  0.000183  0.003780            0.989246\n",
       "avg         5.5  0.859674  0.000215  0.003972            0.968751"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame(zip(estimators,rf_r2,rf_mse,rf_mae,pearsoncorr))\n",
    "result.columns = ['Estimators','R2Score','MSE','MAE','Correlation Coeff.']\n",
    "result.loc[len(estimators)] = result.mean(numeric_only=True, axis=0)\n",
    "result.rename(index={len(estimators):'avg'},inplace=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "id": "ku-f0Bdn5u_A"
   },
   "outputs": [],
   "source": [
    "result.to_csv(dir+'Results/EGEOD75140/RFRegression_10runs.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "EGEOD75140_scRNAseqTimeSeries.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
